// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        v3.21.12
// source: yandex/cloud/ai/stt/v2/stt_service.proto

package stt

import (
	_ "github.com/yandex-cloud/go-genproto/yandex/cloud/api"
	operation "github.com/yandex-cloud/go-genproto/yandex/cloud/operation"
	_ "google.golang.org/genproto/googleapis/api/annotations"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	durationpb "google.golang.org/protobuf/types/known/durationpb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type RecognitionSpec_AudioEncoding int32

const (
	RecognitionSpec_AUDIO_ENCODING_UNSPECIFIED RecognitionSpec_AudioEncoding = 0
	// 16-bit signed little-endian (Linear PCM)
	RecognitionSpec_LINEAR16_PCM RecognitionSpec_AudioEncoding = 1
	RecognitionSpec_OGG_OPUS     RecognitionSpec_AudioEncoding = 2
	// transcription only
	RecognitionSpec_MP3 RecognitionSpec_AudioEncoding = 3
)

// Enum value maps for RecognitionSpec_AudioEncoding.
var (
	RecognitionSpec_AudioEncoding_name = map[int32]string{
		0: "AUDIO_ENCODING_UNSPECIFIED",
		1: "LINEAR16_PCM",
		2: "OGG_OPUS",
		3: "MP3",
	}
	RecognitionSpec_AudioEncoding_value = map[string]int32{
		"AUDIO_ENCODING_UNSPECIFIED": 0,
		"LINEAR16_PCM":               1,
		"OGG_OPUS":                   2,
		"MP3":                        3,
	}
)

func (x RecognitionSpec_AudioEncoding) Enum() *RecognitionSpec_AudioEncoding {
	p := new(RecognitionSpec_AudioEncoding)
	*p = x
	return p
}

func (x RecognitionSpec_AudioEncoding) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (RecognitionSpec_AudioEncoding) Descriptor() protoreflect.EnumDescriptor {
	return file_yandex_cloud_ai_stt_v2_stt_service_proto_enumTypes[0].Descriptor()
}

func (RecognitionSpec_AudioEncoding) Type() protoreflect.EnumType {
	return &file_yandex_cloud_ai_stt_v2_stt_service_proto_enumTypes[0]
}

func (x RecognitionSpec_AudioEncoding) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use RecognitionSpec_AudioEncoding.Descriptor instead.
func (RecognitionSpec_AudioEncoding) EnumDescriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescGZIP(), []int{6, 0}
}

type LongRunningRecognitionRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Config        *RecognitionConfig     `protobuf:"bytes,1,opt,name=config,proto3" json:"config,omitempty"`
	Audio         *RecognitionAudio      `protobuf:"bytes,2,opt,name=audio,proto3" json:"audio,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LongRunningRecognitionRequest) Reset() {
	*x = LongRunningRecognitionRequest{}
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LongRunningRecognitionRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LongRunningRecognitionRequest) ProtoMessage() {}

func (x *LongRunningRecognitionRequest) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LongRunningRecognitionRequest.ProtoReflect.Descriptor instead.
func (*LongRunningRecognitionRequest) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescGZIP(), []int{0}
}

func (x *LongRunningRecognitionRequest) GetConfig() *RecognitionConfig {
	if x != nil {
		return x.Config
	}
	return nil
}

func (x *LongRunningRecognitionRequest) GetAudio() *RecognitionAudio {
	if x != nil {
		return x.Audio
	}
	return nil
}

type LongRunningRecognitionResponse struct {
	state         protoimpl.MessageState     `protogen:"open.v1"`
	Chunks        []*SpeechRecognitionResult `protobuf:"bytes,1,rep,name=chunks,proto3" json:"chunks,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LongRunningRecognitionResponse) Reset() {
	*x = LongRunningRecognitionResponse{}
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LongRunningRecognitionResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LongRunningRecognitionResponse) ProtoMessage() {}

func (x *LongRunningRecognitionResponse) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LongRunningRecognitionResponse.ProtoReflect.Descriptor instead.
func (*LongRunningRecognitionResponse) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescGZIP(), []int{1}
}

func (x *LongRunningRecognitionResponse) GetChunks() []*SpeechRecognitionResult {
	if x != nil {
		return x.Chunks
	}
	return nil
}

type StreamingRecognitionRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to StreamingRequest:
	//
	//	*StreamingRecognitionRequest_Config
	//	*StreamingRecognitionRequest_AudioContent
	StreamingRequest isStreamingRecognitionRequest_StreamingRequest `protobuf_oneof:"streaming_request"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *StreamingRecognitionRequest) Reset() {
	*x = StreamingRecognitionRequest{}
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StreamingRecognitionRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamingRecognitionRequest) ProtoMessage() {}

func (x *StreamingRecognitionRequest) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamingRecognitionRequest.ProtoReflect.Descriptor instead.
func (*StreamingRecognitionRequest) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescGZIP(), []int{2}
}

func (x *StreamingRecognitionRequest) GetStreamingRequest() isStreamingRecognitionRequest_StreamingRequest {
	if x != nil {
		return x.StreamingRequest
	}
	return nil
}

func (x *StreamingRecognitionRequest) GetConfig() *RecognitionConfig {
	if x != nil {
		if x, ok := x.StreamingRequest.(*StreamingRecognitionRequest_Config); ok {
			return x.Config
		}
	}
	return nil
}

func (x *StreamingRecognitionRequest) GetAudioContent() []byte {
	if x != nil {
		if x, ok := x.StreamingRequest.(*StreamingRecognitionRequest_AudioContent); ok {
			return x.AudioContent
		}
	}
	return nil
}

type isStreamingRecognitionRequest_StreamingRequest interface {
	isStreamingRecognitionRequest_StreamingRequest()
}

type StreamingRecognitionRequest_Config struct {
	Config *RecognitionConfig `protobuf:"bytes,1,opt,name=config,proto3,oneof"`
}

type StreamingRecognitionRequest_AudioContent struct {
	AudioContent []byte `protobuf:"bytes,2,opt,name=audio_content,json=audioContent,proto3,oneof"`
}

func (*StreamingRecognitionRequest_Config) isStreamingRecognitionRequest_StreamingRequest() {}

func (*StreamingRecognitionRequest_AudioContent) isStreamingRecognitionRequest_StreamingRequest() {}

type StreamingRecognitionResponse struct {
	state         protoimpl.MessageState    `protogen:"open.v1"`
	Chunks        []*SpeechRecognitionChunk `protobuf:"bytes,1,rep,name=chunks,proto3" json:"chunks,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StreamingRecognitionResponse) Reset() {
	*x = StreamingRecognitionResponse{}
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StreamingRecognitionResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamingRecognitionResponse) ProtoMessage() {}

func (x *StreamingRecognitionResponse) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamingRecognitionResponse.ProtoReflect.Descriptor instead.
func (*StreamingRecognitionResponse) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescGZIP(), []int{3}
}

func (x *StreamingRecognitionResponse) GetChunks() []*SpeechRecognitionChunk {
	if x != nil {
		return x.Chunks
	}
	return nil
}

type RecognitionAudio struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to AudioSource:
	//
	//	*RecognitionAudio_Content
	//	*RecognitionAudio_Uri
	AudioSource   isRecognitionAudio_AudioSource `protobuf_oneof:"audio_source"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RecognitionAudio) Reset() {
	*x = RecognitionAudio{}
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RecognitionAudio) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionAudio) ProtoMessage() {}

func (x *RecognitionAudio) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionAudio.ProtoReflect.Descriptor instead.
func (*RecognitionAudio) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescGZIP(), []int{4}
}

func (x *RecognitionAudio) GetAudioSource() isRecognitionAudio_AudioSource {
	if x != nil {
		return x.AudioSource
	}
	return nil
}

func (x *RecognitionAudio) GetContent() []byte {
	if x != nil {
		if x, ok := x.AudioSource.(*RecognitionAudio_Content); ok {
			return x.Content
		}
	}
	return nil
}

func (x *RecognitionAudio) GetUri() string {
	if x != nil {
		if x, ok := x.AudioSource.(*RecognitionAudio_Uri); ok {
			return x.Uri
		}
	}
	return ""
}

type isRecognitionAudio_AudioSource interface {
	isRecognitionAudio_AudioSource()
}

type RecognitionAudio_Content struct {
	Content []byte `protobuf:"bytes,1,opt,name=content,proto3,oneof"`
}

type RecognitionAudio_Uri struct {
	Uri string `protobuf:"bytes,2,opt,name=uri,proto3,oneof"`
}

func (*RecognitionAudio_Content) isRecognitionAudio_AudioSource() {}

func (*RecognitionAudio_Uri) isRecognitionAudio_AudioSource() {}

type RecognitionConfig struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Specification *RecognitionSpec       `protobuf:"bytes,1,opt,name=specification,proto3" json:"specification,omitempty"`
	FolderId      string                 `protobuf:"bytes,2,opt,name=folder_id,json=folderId,proto3" json:"folder_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RecognitionConfig) Reset() {
	*x = RecognitionConfig{}
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RecognitionConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionConfig) ProtoMessage() {}

func (x *RecognitionConfig) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionConfig.ProtoReflect.Descriptor instead.
func (*RecognitionConfig) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescGZIP(), []int{5}
}

func (x *RecognitionConfig) GetSpecification() *RecognitionSpec {
	if x != nil {
		return x.Specification
	}
	return nil
}

func (x *RecognitionConfig) GetFolderId() string {
	if x != nil {
		return x.FolderId
	}
	return ""
}

type RecognitionSpec struct {
	state         protoimpl.MessageState        `protogen:"open.v1"`
	AudioEncoding RecognitionSpec_AudioEncoding `protobuf:"varint,1,opt,name=audio_encoding,json=audioEncoding,proto3,enum=yandex.cloud.ai.stt.v2.RecognitionSpec_AudioEncoding" json:"audio_encoding,omitempty"`
	// 8000, 16000, 48000 only for pcm
	SampleRateHertz int64 `protobuf:"varint,2,opt,name=sample_rate_hertz,json=sampleRateHertz,proto3" json:"sample_rate_hertz,omitempty"`
	// code in BCP-47
	LanguageCode    string `protobuf:"bytes,3,opt,name=language_code,json=languageCode,proto3" json:"language_code,omitempty"`
	ProfanityFilter bool   `protobuf:"varint,4,opt,name=profanity_filter,json=profanityFilter,proto3" json:"profanity_filter,omitempty"`
	Model           string `protobuf:"bytes,5,opt,name=model,proto3" json:"model,omitempty"`
	// If set true, tentative hypotheses may be returned as they become available (final=false flag)
	// If false or omitted, only final=true result(s) are returned.
	// Makes sense only for StreamingRecognize requests.
	PartialResults  bool `protobuf:"varint,7,opt,name=partial_results,json=partialResults,proto3" json:"partial_results,omitempty"`
	SingleUtterance bool `protobuf:"varint,8,opt,name=single_utterance,json=singleUtterance,proto3" json:"single_utterance,omitempty"`
	// Used only for long running recognize.
	AudioChannelCount int64 `protobuf:"varint,9,opt,name=audio_channel_count,json=audioChannelCount,proto3" json:"audio_channel_count,omitempty"`
	// This mark allows disable normalization text
	RawResults bool `protobuf:"varint,10,opt,name=raw_results,json=rawResults,proto3" json:"raw_results,omitempty"`
	// Rewrite text in literature style (default: false)
	LiteratureText bool `protobuf:"varint,11,opt,name=literature_text,json=literatureText,proto3" json:"literature_text,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *RecognitionSpec) Reset() {
	*x = RecognitionSpec{}
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RecognitionSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionSpec) ProtoMessage() {}

func (x *RecognitionSpec) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionSpec.ProtoReflect.Descriptor instead.
func (*RecognitionSpec) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescGZIP(), []int{6}
}

func (x *RecognitionSpec) GetAudioEncoding() RecognitionSpec_AudioEncoding {
	if x != nil {
		return x.AudioEncoding
	}
	return RecognitionSpec_AUDIO_ENCODING_UNSPECIFIED
}

func (x *RecognitionSpec) GetSampleRateHertz() int64 {
	if x != nil {
		return x.SampleRateHertz
	}
	return 0
}

func (x *RecognitionSpec) GetLanguageCode() string {
	if x != nil {
		return x.LanguageCode
	}
	return ""
}

func (x *RecognitionSpec) GetProfanityFilter() bool {
	if x != nil {
		return x.ProfanityFilter
	}
	return false
}

func (x *RecognitionSpec) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *RecognitionSpec) GetPartialResults() bool {
	if x != nil {
		return x.PartialResults
	}
	return false
}

func (x *RecognitionSpec) GetSingleUtterance() bool {
	if x != nil {
		return x.SingleUtterance
	}
	return false
}

func (x *RecognitionSpec) GetAudioChannelCount() int64 {
	if x != nil {
		return x.AudioChannelCount
	}
	return 0
}

func (x *RecognitionSpec) GetRawResults() bool {
	if x != nil {
		return x.RawResults
	}
	return false
}

func (x *RecognitionSpec) GetLiteratureText() bool {
	if x != nil {
		return x.LiteratureText
	}
	return false
}

type SpeechRecognitionChunk struct {
	state        protoimpl.MessageState          `protogen:"open.v1"`
	Alternatives []*SpeechRecognitionAlternative `protobuf:"bytes,1,rep,name=alternatives,proto3" json:"alternatives,omitempty"`
	// This flag shows that the received chunk contains a part of the recognized text that won't be changed.
	Final bool `protobuf:"varint,2,opt,name=final,proto3" json:"final,omitempty"`
	// This flag shows that the received chunk is the end of an utterance.
	EndOfUtterance bool `protobuf:"varint,3,opt,name=end_of_utterance,json=endOfUtterance,proto3" json:"end_of_utterance,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *SpeechRecognitionChunk) Reset() {
	*x = SpeechRecognitionChunk{}
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechRecognitionChunk) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechRecognitionChunk) ProtoMessage() {}

func (x *SpeechRecognitionChunk) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SpeechRecognitionChunk.ProtoReflect.Descriptor instead.
func (*SpeechRecognitionChunk) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescGZIP(), []int{7}
}

func (x *SpeechRecognitionChunk) GetAlternatives() []*SpeechRecognitionAlternative {
	if x != nil {
		return x.Alternatives
	}
	return nil
}

func (x *SpeechRecognitionChunk) GetFinal() bool {
	if x != nil {
		return x.Final
	}
	return false
}

func (x *SpeechRecognitionChunk) GetEndOfUtterance() bool {
	if x != nil {
		return x.EndOfUtterance
	}
	return false
}

type SpeechRecognitionResult struct {
	state         protoimpl.MessageState          `protogen:"open.v1"`
	Alternatives  []*SpeechRecognitionAlternative `protobuf:"bytes,1,rep,name=alternatives,proto3" json:"alternatives,omitempty"`
	ChannelTag    int64                           `protobuf:"varint,2,opt,name=channel_tag,json=channelTag,proto3" json:"channel_tag,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SpeechRecognitionResult) Reset() {
	*x = SpeechRecognitionResult{}
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechRecognitionResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechRecognitionResult) ProtoMessage() {}

func (x *SpeechRecognitionResult) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SpeechRecognitionResult.ProtoReflect.Descriptor instead.
func (*SpeechRecognitionResult) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescGZIP(), []int{8}
}

func (x *SpeechRecognitionResult) GetAlternatives() []*SpeechRecognitionAlternative {
	if x != nil {
		return x.Alternatives
	}
	return nil
}

func (x *SpeechRecognitionResult) GetChannelTag() int64 {
	if x != nil {
		return x.ChannelTag
	}
	return 0
}

type SpeechRecognitionAlternative struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Text          string                 `protobuf:"bytes,1,opt,name=text,proto3" json:"text,omitempty"`
	Confidence    float32                `protobuf:"fixed32,2,opt,name=confidence,proto3" json:"confidence,omitempty"`
	Words         []*WordInfo            `protobuf:"bytes,3,rep,name=words,proto3" json:"words,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SpeechRecognitionAlternative) Reset() {
	*x = SpeechRecognitionAlternative{}
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechRecognitionAlternative) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechRecognitionAlternative) ProtoMessage() {}

func (x *SpeechRecognitionAlternative) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SpeechRecognitionAlternative.ProtoReflect.Descriptor instead.
func (*SpeechRecognitionAlternative) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescGZIP(), []int{9}
}

func (x *SpeechRecognitionAlternative) GetText() string {
	if x != nil {
		return x.Text
	}
	return ""
}

func (x *SpeechRecognitionAlternative) GetConfidence() float32 {
	if x != nil {
		return x.Confidence
	}
	return 0
}

func (x *SpeechRecognitionAlternative) GetWords() []*WordInfo {
	if x != nil {
		return x.Words
	}
	return nil
}

type WordInfo struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	StartTime     *durationpb.Duration   `protobuf:"bytes,1,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"`
	EndTime       *durationpb.Duration   `protobuf:"bytes,2,opt,name=end_time,json=endTime,proto3" json:"end_time,omitempty"`
	Word          string                 `protobuf:"bytes,3,opt,name=word,proto3" json:"word,omitempty"`
	Confidence    float32                `protobuf:"fixed32,4,opt,name=confidence,proto3" json:"confidence,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *WordInfo) Reset() {
	*x = WordInfo{}
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *WordInfo) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*WordInfo) ProtoMessage() {}

func (x *WordInfo) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use WordInfo.ProtoReflect.Descriptor instead.
func (*WordInfo) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescGZIP(), []int{10}
}

func (x *WordInfo) GetStartTime() *durationpb.Duration {
	if x != nil {
		return x.StartTime
	}
	return nil
}

func (x *WordInfo) GetEndTime() *durationpb.Duration {
	if x != nil {
		return x.EndTime
	}
	return nil
}

func (x *WordInfo) GetWord() string {
	if x != nil {
		return x.Word
	}
	return ""
}

func (x *WordInfo) GetConfidence() float32 {
	if x != nil {
		return x.Confidence
	}
	return 0
}

var File_yandex_cloud_ai_stt_v2_stt_service_proto protoreflect.FileDescriptor

const file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDesc = "" +
	"\n" +
	"(yandex/cloud/ai/stt/v2/stt_service.proto\x12\x16yandex.cloud.ai.stt.v2\x1a\x1cgoogle/api/annotations.proto\x1a\x1egoogle/protobuf/duration.proto\x1a yandex/cloud/api/operation.proto\x1a&yandex/cloud/operation/operation.proto\"\xa2\x01\n" +
	"\x1dLongRunningRecognitionRequest\x12A\n" +
	"\x06config\x18\x01 \x01(\v2).yandex.cloud.ai.stt.v2.RecognitionConfigR\x06config\x12>\n" +
	"\x05audio\x18\x02 \x01(\v2(.yandex.cloud.ai.stt.v2.RecognitionAudioR\x05audio\"i\n" +
	"\x1eLongRunningRecognitionResponse\x12G\n" +
	"\x06chunks\x18\x01 \x03(\v2/.yandex.cloud.ai.stt.v2.SpeechRecognitionResultR\x06chunks\"\x9e\x01\n" +
	"\x1bStreamingRecognitionRequest\x12C\n" +
	"\x06config\x18\x01 \x01(\v2).yandex.cloud.ai.stt.v2.RecognitionConfigH\x00R\x06config\x12%\n" +
	"\raudio_content\x18\x02 \x01(\fH\x00R\faudioContentB\x13\n" +
	"\x11streaming_request\"\x85\x01\n" +
	"\x1cStreamingRecognitionResponse\x12F\n" +
	"\x06chunks\x18\x01 \x03(\v2..yandex.cloud.ai.stt.v2.SpeechRecognitionChunkR\x06chunksJ\x04\b\x02\x10\x03R\x17end_of_single_utterance\"R\n" +
	"\x10RecognitionAudio\x12\x1a\n" +
	"\acontent\x18\x01 \x01(\fH\x00R\acontent\x12\x12\n" +
	"\x03uri\x18\x02 \x01(\tH\x00R\x03uriB\x0e\n" +
	"\faudio_source\"\x7f\n" +
	"\x11RecognitionConfig\x12M\n" +
	"\rspecification\x18\x01 \x01(\v2'.yandex.cloud.ai.stt.v2.RecognitionSpecR\rspecification\x12\x1b\n" +
	"\tfolder_id\x18\x02 \x01(\tR\bfolderId\"\xaf\x04\n" +
	"\x0fRecognitionSpec\x12\\\n" +
	"\x0eaudio_encoding\x18\x01 \x01(\x0e25.yandex.cloud.ai.stt.v2.RecognitionSpec.AudioEncodingR\raudioEncoding\x12*\n" +
	"\x11sample_rate_hertz\x18\x02 \x01(\x03R\x0fsampleRateHertz\x12#\n" +
	"\rlanguage_code\x18\x03 \x01(\tR\flanguageCode\x12)\n" +
	"\x10profanity_filter\x18\x04 \x01(\bR\x0fprofanityFilter\x12\x14\n" +
	"\x05model\x18\x05 \x01(\tR\x05model\x12'\n" +
	"\x0fpartial_results\x18\a \x01(\bR\x0epartialResults\x12)\n" +
	"\x10single_utterance\x18\b \x01(\bR\x0fsingleUtterance\x12.\n" +
	"\x13audio_channel_count\x18\t \x01(\x03R\x11audioChannelCount\x12\x1f\n" +
	"\vraw_results\x18\n" +
	" \x01(\bR\n" +
	"rawResults\x12'\n" +
	"\x0fliterature_text\x18\v \x01(\bR\x0eliteratureText\"X\n" +
	"\rAudioEncoding\x12\x1e\n" +
	"\x1aAUDIO_ENCODING_UNSPECIFIED\x10\x00\x12\x10\n" +
	"\fLINEAR16_PCM\x10\x01\x12\f\n" +
	"\bOGG_OPUS\x10\x02\x12\a\n" +
	"\x03MP3\x10\x03J\x04\b\x06\x10\a\"\xb2\x01\n" +
	"\x16SpeechRecognitionChunk\x12X\n" +
	"\falternatives\x18\x01 \x03(\v24.yandex.cloud.ai.stt.v2.SpeechRecognitionAlternativeR\falternatives\x12\x14\n" +
	"\x05final\x18\x02 \x01(\bR\x05final\x12(\n" +
	"\x10end_of_utterance\x18\x03 \x01(\bR\x0eendOfUtterance\"\x94\x01\n" +
	"\x17SpeechRecognitionResult\x12X\n" +
	"\falternatives\x18\x01 \x03(\v24.yandex.cloud.ai.stt.v2.SpeechRecognitionAlternativeR\falternatives\x12\x1f\n" +
	"\vchannel_tag\x18\x02 \x01(\x03R\n" +
	"channelTag\"\x8a\x01\n" +
	"\x1cSpeechRecognitionAlternative\x12\x12\n" +
	"\x04text\x18\x01 \x01(\tR\x04text\x12\x1e\n" +
	"\n" +
	"confidence\x18\x02 \x01(\x02R\n" +
	"confidence\x126\n" +
	"\x05words\x18\x03 \x03(\v2 .yandex.cloud.ai.stt.v2.WordInfoR\x05words\"\xae\x01\n" +
	"\bWordInfo\x128\n" +
	"\n" +
	"start_time\x18\x01 \x01(\v2\x19.google.protobuf.DurationR\tstartTime\x124\n" +
	"\bend_time\x18\x02 \x01(\v2\x19.google.protobuf.DurationR\aendTime\x12\x12\n" +
	"\x04word\x18\x03 \x01(\tR\x04word\x12\x1e\n" +
	"\n" +
	"confidence\x18\x04 \x01(\x02R\n" +
	"confidence2\xdb\x02\n" +
	"\n" +
	"SttService\x12\xc4\x01\n" +
	"\x14LongRunningRecognize\x125.yandex.cloud.ai.stt.v2.LongRunningRecognitionRequest\x1a!.yandex.cloud.operation.Operation\"R\xb2\xd2* \x12\x1eLongRunningRecognitionResponse\x82\xd3\xe4\x93\x02(:\x01*\"#/speech/stt/v2/longRunningRecognize\x12\x85\x01\n" +
	"\x12StreamingRecognize\x123.yandex.cloud.ai.stt.v2.StreamingRecognitionRequest\x1a4.yandex.cloud.ai.stt.v2.StreamingRecognitionResponse\"\x00(\x010\x01B\\\n" +
	"\x1ayandex.cloud.api.ai.stt.v2Z>github.com/yandex-cloud/go-genproto/yandex/cloud/ai/stt/v2;sttb\x06proto3"

var (
	file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescOnce sync.Once
	file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescData []byte
)

func file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescGZIP() []byte {
	file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescOnce.Do(func() {
		file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDesc), len(file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDesc)))
	})
	return file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDescData
}

var file_yandex_cloud_ai_stt_v2_stt_service_proto_enumTypes = make([]protoimpl.EnumInfo, 1)
var file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes = make([]protoimpl.MessageInfo, 11)
var file_yandex_cloud_ai_stt_v2_stt_service_proto_goTypes = []any{
	(RecognitionSpec_AudioEncoding)(0),     // 0: yandex.cloud.ai.stt.v2.RecognitionSpec.AudioEncoding
	(*LongRunningRecognitionRequest)(nil),  // 1: yandex.cloud.ai.stt.v2.LongRunningRecognitionRequest
	(*LongRunningRecognitionResponse)(nil), // 2: yandex.cloud.ai.stt.v2.LongRunningRecognitionResponse
	(*StreamingRecognitionRequest)(nil),    // 3: yandex.cloud.ai.stt.v2.StreamingRecognitionRequest
	(*StreamingRecognitionResponse)(nil),   // 4: yandex.cloud.ai.stt.v2.StreamingRecognitionResponse
	(*RecognitionAudio)(nil),               // 5: yandex.cloud.ai.stt.v2.RecognitionAudio
	(*RecognitionConfig)(nil),              // 6: yandex.cloud.ai.stt.v2.RecognitionConfig
	(*RecognitionSpec)(nil),                // 7: yandex.cloud.ai.stt.v2.RecognitionSpec
	(*SpeechRecognitionChunk)(nil),         // 8: yandex.cloud.ai.stt.v2.SpeechRecognitionChunk
	(*SpeechRecognitionResult)(nil),        // 9: yandex.cloud.ai.stt.v2.SpeechRecognitionResult
	(*SpeechRecognitionAlternative)(nil),   // 10: yandex.cloud.ai.stt.v2.SpeechRecognitionAlternative
	(*WordInfo)(nil),                       // 11: yandex.cloud.ai.stt.v2.WordInfo
	(*durationpb.Duration)(nil),            // 12: google.protobuf.Duration
	(*operation.Operation)(nil),            // 13: yandex.cloud.operation.Operation
}
var file_yandex_cloud_ai_stt_v2_stt_service_proto_depIdxs = []int32{
	6,  // 0: yandex.cloud.ai.stt.v2.LongRunningRecognitionRequest.config:type_name -> yandex.cloud.ai.stt.v2.RecognitionConfig
	5,  // 1: yandex.cloud.ai.stt.v2.LongRunningRecognitionRequest.audio:type_name -> yandex.cloud.ai.stt.v2.RecognitionAudio
	9,  // 2: yandex.cloud.ai.stt.v2.LongRunningRecognitionResponse.chunks:type_name -> yandex.cloud.ai.stt.v2.SpeechRecognitionResult
	6,  // 3: yandex.cloud.ai.stt.v2.StreamingRecognitionRequest.config:type_name -> yandex.cloud.ai.stt.v2.RecognitionConfig
	8,  // 4: yandex.cloud.ai.stt.v2.StreamingRecognitionResponse.chunks:type_name -> yandex.cloud.ai.stt.v2.SpeechRecognitionChunk
	7,  // 5: yandex.cloud.ai.stt.v2.RecognitionConfig.specification:type_name -> yandex.cloud.ai.stt.v2.RecognitionSpec
	0,  // 6: yandex.cloud.ai.stt.v2.RecognitionSpec.audio_encoding:type_name -> yandex.cloud.ai.stt.v2.RecognitionSpec.AudioEncoding
	10, // 7: yandex.cloud.ai.stt.v2.SpeechRecognitionChunk.alternatives:type_name -> yandex.cloud.ai.stt.v2.SpeechRecognitionAlternative
	10, // 8: yandex.cloud.ai.stt.v2.SpeechRecognitionResult.alternatives:type_name -> yandex.cloud.ai.stt.v2.SpeechRecognitionAlternative
	11, // 9: yandex.cloud.ai.stt.v2.SpeechRecognitionAlternative.words:type_name -> yandex.cloud.ai.stt.v2.WordInfo
	12, // 10: yandex.cloud.ai.stt.v2.WordInfo.start_time:type_name -> google.protobuf.Duration
	12, // 11: yandex.cloud.ai.stt.v2.WordInfo.end_time:type_name -> google.protobuf.Duration
	1,  // 12: yandex.cloud.ai.stt.v2.SttService.LongRunningRecognize:input_type -> yandex.cloud.ai.stt.v2.LongRunningRecognitionRequest
	3,  // 13: yandex.cloud.ai.stt.v2.SttService.StreamingRecognize:input_type -> yandex.cloud.ai.stt.v2.StreamingRecognitionRequest
	13, // 14: yandex.cloud.ai.stt.v2.SttService.LongRunningRecognize:output_type -> yandex.cloud.operation.Operation
	4,  // 15: yandex.cloud.ai.stt.v2.SttService.StreamingRecognize:output_type -> yandex.cloud.ai.stt.v2.StreamingRecognitionResponse
	14, // [14:16] is the sub-list for method output_type
	12, // [12:14] is the sub-list for method input_type
	12, // [12:12] is the sub-list for extension type_name
	12, // [12:12] is the sub-list for extension extendee
	0,  // [0:12] is the sub-list for field type_name
}

func init() { file_yandex_cloud_ai_stt_v2_stt_service_proto_init() }
func file_yandex_cloud_ai_stt_v2_stt_service_proto_init() {
	if File_yandex_cloud_ai_stt_v2_stt_service_proto != nil {
		return
	}
	file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[2].OneofWrappers = []any{
		(*StreamingRecognitionRequest_Config)(nil),
		(*StreamingRecognitionRequest_AudioContent)(nil),
	}
	file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes[4].OneofWrappers = []any{
		(*RecognitionAudio_Content)(nil),
		(*RecognitionAudio_Uri)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDesc), len(file_yandex_cloud_ai_stt_v2_stt_service_proto_rawDesc)),
			NumEnums:      1,
			NumMessages:   11,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_yandex_cloud_ai_stt_v2_stt_service_proto_goTypes,
		DependencyIndexes: file_yandex_cloud_ai_stt_v2_stt_service_proto_depIdxs,
		EnumInfos:         file_yandex_cloud_ai_stt_v2_stt_service_proto_enumTypes,
		MessageInfos:      file_yandex_cloud_ai_stt_v2_stt_service_proto_msgTypes,
	}.Build()
	File_yandex_cloud_ai_stt_v2_stt_service_proto = out.File
	file_yandex_cloud_ai_stt_v2_stt_service_proto_goTypes = nil
	file_yandex_cloud_ai_stt_v2_stt_service_proto_depIdxs = nil
}

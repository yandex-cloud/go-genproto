// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        v3.21.12
// source: yandex/cloud/ai/tts/v3/tts.proto

package tts

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Specifies the loudness normalization algorithm to use when synthesizing audio.
type LoudnessNormalizationType int32

const (
	// Unspecified loudness normalization. The default behavior will be used.
	LoudnessNormalizationType_LOUDNESS_NORMALIZATION_TYPE_UNSPECIFIED LoudnessNormalizationType = 0
	// The type of normalization, wherein the gain is changed to bring the highest PCM sample value or analog signal peak to a given level.
	LoudnessNormalizationType_MAX_PEAK LoudnessNormalizationType = 1
	// The type of normalization based on EBU R 128 recommendation.
	LoudnessNormalizationType_LUFS LoudnessNormalizationType = 2
)

// Enum value maps for LoudnessNormalizationType.
var (
	LoudnessNormalizationType_name = map[int32]string{
		0: "LOUDNESS_NORMALIZATION_TYPE_UNSPECIFIED",
		1: "MAX_PEAK",
		2: "LUFS",
	}
	LoudnessNormalizationType_value = map[string]int32{
		"LOUDNESS_NORMALIZATION_TYPE_UNSPECIFIED": 0,
		"MAX_PEAK": 1,
		"LUFS":     2,
	}
)

func (x LoudnessNormalizationType) Enum() *LoudnessNormalizationType {
	p := new(LoudnessNormalizationType)
	*p = x
	return p
}

func (x LoudnessNormalizationType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (LoudnessNormalizationType) Descriptor() protoreflect.EnumDescriptor {
	return file_yandex_cloud_ai_tts_v3_tts_proto_enumTypes[0].Descriptor()
}

func (LoudnessNormalizationType) Type() protoreflect.EnumType {
	return &file_yandex_cloud_ai_tts_v3_tts_proto_enumTypes[0]
}

func (x LoudnessNormalizationType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use LoudnessNormalizationType.Descriptor instead.
func (LoudnessNormalizationType) EnumDescriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{0}
}

type RawAudio_AudioEncoding int32

const (
	RawAudio_AUDIO_ENCODING_UNSPECIFIED RawAudio_AudioEncoding = 0
	// Audio bit depth 16-bit signed little-endian (Linear PCM).
	RawAudio_LINEAR16_PCM RawAudio_AudioEncoding = 1
)

// Enum value maps for RawAudio_AudioEncoding.
var (
	RawAudio_AudioEncoding_name = map[int32]string{
		0: "AUDIO_ENCODING_UNSPECIFIED",
		1: "LINEAR16_PCM",
	}
	RawAudio_AudioEncoding_value = map[string]int32{
		"AUDIO_ENCODING_UNSPECIFIED": 0,
		"LINEAR16_PCM":               1,
	}
)

func (x RawAudio_AudioEncoding) Enum() *RawAudio_AudioEncoding {
	p := new(RawAudio_AudioEncoding)
	*p = x
	return p
}

func (x RawAudio_AudioEncoding) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (RawAudio_AudioEncoding) Descriptor() protoreflect.EnumDescriptor {
	return file_yandex_cloud_ai_tts_v3_tts_proto_enumTypes[1].Descriptor()
}

func (RawAudio_AudioEncoding) Type() protoreflect.EnumType {
	return &file_yandex_cloud_ai_tts_v3_tts_proto_enumTypes[1]
}

func (x RawAudio_AudioEncoding) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use RawAudio_AudioEncoding.Descriptor instead.
func (RawAudio_AudioEncoding) EnumDescriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{2, 0}
}

type ContainerAudio_ContainerAudioType int32

const (
	ContainerAudio_CONTAINER_AUDIO_TYPE_UNSPECIFIED ContainerAudio_ContainerAudioType = 0
	// Audio bit depth 16-bit signed little-endian (Linear PCM).
	ContainerAudio_WAV ContainerAudio_ContainerAudioType = 1
	// Data is encoded using the OPUS audio codec and compressed using the OGG container format.
	ContainerAudio_OGG_OPUS ContainerAudio_ContainerAudioType = 2
	// Data is encoded using MPEG-1/2 Layer III and compressed using the MP3 container format.
	ContainerAudio_MP3 ContainerAudio_ContainerAudioType = 3
)

// Enum value maps for ContainerAudio_ContainerAudioType.
var (
	ContainerAudio_ContainerAudioType_name = map[int32]string{
		0: "CONTAINER_AUDIO_TYPE_UNSPECIFIED",
		1: "WAV",
		2: "OGG_OPUS",
		3: "MP3",
	}
	ContainerAudio_ContainerAudioType_value = map[string]int32{
		"CONTAINER_AUDIO_TYPE_UNSPECIFIED": 0,
		"WAV":                              1,
		"OGG_OPUS":                         2,
		"MP3":                              3,
	}
)

func (x ContainerAudio_ContainerAudioType) Enum() *ContainerAudio_ContainerAudioType {
	p := new(ContainerAudio_ContainerAudioType)
	*p = x
	return p
}

func (x ContainerAudio_ContainerAudioType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ContainerAudio_ContainerAudioType) Descriptor() protoreflect.EnumDescriptor {
	return file_yandex_cloud_ai_tts_v3_tts_proto_enumTypes[2].Descriptor()
}

func (ContainerAudio_ContainerAudioType) Type() protoreflect.EnumType {
	return &file_yandex_cloud_ai_tts_v3_tts_proto_enumTypes[2]
}

func (x ContainerAudio_ContainerAudioType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ContainerAudio_ContainerAudioType.Descriptor instead.
func (ContainerAudio_ContainerAudioType) EnumDescriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{3, 0}
}

type DurationHint_DurationHintPolicy int32

const (
	DurationHint_DURATION_HINT_POLICY_UNSPECIFIED DurationHint_DurationHintPolicy = 0
	// Limit audio duration to exact value.
	DurationHint_EXACT_DURATION DurationHint_DurationHintPolicy = 1
	// Limit the minimum audio duration.
	DurationHint_MIN_DURATION DurationHint_DurationHintPolicy = 2
	// Limit the maximum audio duration.
	DurationHint_MAX_DURATION DurationHint_DurationHintPolicy = 3
)

// Enum value maps for DurationHint_DurationHintPolicy.
var (
	DurationHint_DurationHintPolicy_name = map[int32]string{
		0: "DURATION_HINT_POLICY_UNSPECIFIED",
		1: "EXACT_DURATION",
		2: "MIN_DURATION",
		3: "MAX_DURATION",
	}
	DurationHint_DurationHintPolicy_value = map[string]int32{
		"DURATION_HINT_POLICY_UNSPECIFIED": 0,
		"EXACT_DURATION":                   1,
		"MIN_DURATION":                     2,
		"MAX_DURATION":                     3,
	}
)

func (x DurationHint_DurationHintPolicy) Enum() *DurationHint_DurationHintPolicy {
	p := new(DurationHint_DurationHintPolicy)
	*p = x
	return p
}

func (x DurationHint_DurationHintPolicy) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (DurationHint_DurationHintPolicy) Descriptor() protoreflect.EnumDescriptor {
	return file_yandex_cloud_ai_tts_v3_tts_proto_enumTypes[3].Descriptor()
}

func (DurationHint_DurationHintPolicy) Type() protoreflect.EnumType {
	return &file_yandex_cloud_ai_tts_v3_tts_proto_enumTypes[3]
}

func (x DurationHint_DurationHintPolicy) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use DurationHint_DurationHintPolicy.Descriptor instead.
func (DurationHint_DurationHintPolicy) EnumDescriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{11, 0}
}

type UtteranceSynthesisRequest_LoudnessNormalizationType int32

const (
	UtteranceSynthesisRequest_LOUDNESS_NORMALIZATION_TYPE_UNSPECIFIED UtteranceSynthesisRequest_LoudnessNormalizationType = 0
	// The type of normalization, wherein the gain is changed to bring the highest PCM sample value or analog signal peak to a given level.
	UtteranceSynthesisRequest_MAX_PEAK UtteranceSynthesisRequest_LoudnessNormalizationType = 1
	// The type of normalization based on EBU R 128 recommendation.
	UtteranceSynthesisRequest_LUFS UtteranceSynthesisRequest_LoudnessNormalizationType = 2
)

// Enum value maps for UtteranceSynthesisRequest_LoudnessNormalizationType.
var (
	UtteranceSynthesisRequest_LoudnessNormalizationType_name = map[int32]string{
		0: "LOUDNESS_NORMALIZATION_TYPE_UNSPECIFIED",
		1: "MAX_PEAK",
		2: "LUFS",
	}
	UtteranceSynthesisRequest_LoudnessNormalizationType_value = map[string]int32{
		"LOUDNESS_NORMALIZATION_TYPE_UNSPECIFIED": 0,
		"MAX_PEAK": 1,
		"LUFS":     2,
	}
)

func (x UtteranceSynthesisRequest_LoudnessNormalizationType) Enum() *UtteranceSynthesisRequest_LoudnessNormalizationType {
	p := new(UtteranceSynthesisRequest_LoudnessNormalizationType)
	*p = x
	return p
}

func (x UtteranceSynthesisRequest_LoudnessNormalizationType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (UtteranceSynthesisRequest_LoudnessNormalizationType) Descriptor() protoreflect.EnumDescriptor {
	return file_yandex_cloud_ai_tts_v3_tts_proto_enumTypes[4].Descriptor()
}

func (UtteranceSynthesisRequest_LoudnessNormalizationType) Type() protoreflect.EnumType {
	return &file_yandex_cloud_ai_tts_v3_tts_proto_enumTypes[4]
}

func (x UtteranceSynthesisRequest_LoudnessNormalizationType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use UtteranceSynthesisRequest_LoudnessNormalizationType.Descriptor instead.
func (UtteranceSynthesisRequest_LoudnessNormalizationType) EnumDescriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{13, 0}
}

type AudioContent struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The audio source to read the data from.
	//
	// Types that are valid to be assigned to AudioSource:
	//
	//	*AudioContent_Content
	AudioSource isAudioContent_AudioSource `protobuf_oneof:"AudioSource"`
	// Description of the audio format.
	AudioSpec     *AudioFormatOptions `protobuf:"bytes,2,opt,name=audio_spec,json=audioSpec,proto3" json:"audio_spec,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AudioContent) Reset() {
	*x = AudioContent{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AudioContent) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AudioContent) ProtoMessage() {}

func (x *AudioContent) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AudioContent.ProtoReflect.Descriptor instead.
func (*AudioContent) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{0}
}

func (x *AudioContent) GetAudioSource() isAudioContent_AudioSource {
	if x != nil {
		return x.AudioSource
	}
	return nil
}

func (x *AudioContent) GetContent() []byte {
	if x != nil {
		if x, ok := x.AudioSource.(*AudioContent_Content); ok {
			return x.Content
		}
	}
	return nil
}

func (x *AudioContent) GetAudioSpec() *AudioFormatOptions {
	if x != nil {
		return x.AudioSpec
	}
	return nil
}

type isAudioContent_AudioSource interface {
	isAudioContent_AudioSource()
}

type AudioContent_Content struct {
	// Bytes with audio data.
	Content []byte `protobuf:"bytes,1,opt,name=content,proto3,oneof"`
}

func (*AudioContent_Content) isAudioContent_AudioSource() {}

type AudioFormatOptions struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to AudioFormat:
	//
	//	*AudioFormatOptions_RawAudio
	//	*AudioFormatOptions_ContainerAudio
	AudioFormat   isAudioFormatOptions_AudioFormat `protobuf_oneof:"AudioFormat"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AudioFormatOptions) Reset() {
	*x = AudioFormatOptions{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AudioFormatOptions) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AudioFormatOptions) ProtoMessage() {}

func (x *AudioFormatOptions) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AudioFormatOptions.ProtoReflect.Descriptor instead.
func (*AudioFormatOptions) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{1}
}

func (x *AudioFormatOptions) GetAudioFormat() isAudioFormatOptions_AudioFormat {
	if x != nil {
		return x.AudioFormat
	}
	return nil
}

func (x *AudioFormatOptions) GetRawAudio() *RawAudio {
	if x != nil {
		if x, ok := x.AudioFormat.(*AudioFormatOptions_RawAudio); ok {
			return x.RawAudio
		}
	}
	return nil
}

func (x *AudioFormatOptions) GetContainerAudio() *ContainerAudio {
	if x != nil {
		if x, ok := x.AudioFormat.(*AudioFormatOptions_ContainerAudio); ok {
			return x.ContainerAudio
		}
	}
	return nil
}

type isAudioFormatOptions_AudioFormat interface {
	isAudioFormatOptions_AudioFormat()
}

type AudioFormatOptions_RawAudio struct {
	// The audio format specified in request parameters.
	RawAudio *RawAudio `protobuf:"bytes,1,opt,name=raw_audio,json=rawAudio,proto3,oneof"`
}

type AudioFormatOptions_ContainerAudio struct {
	// The audio format specified inside the container metadata.
	ContainerAudio *ContainerAudio `protobuf:"bytes,2,opt,name=container_audio,json=containerAudio,proto3,oneof"`
}

func (*AudioFormatOptions_RawAudio) isAudioFormatOptions_AudioFormat() {}

func (*AudioFormatOptions_ContainerAudio) isAudioFormatOptions_AudioFormat() {}

type RawAudio struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Encoding type.
	AudioEncoding RawAudio_AudioEncoding `protobuf:"varint,1,opt,name=audio_encoding,json=audioEncoding,proto3,enum=speechkit.tts.v3.RawAudio_AudioEncoding" json:"audio_encoding,omitempty"`
	// Sampling frequency of the signal.
	SampleRateHertz int64 `protobuf:"varint,2,opt,name=sample_rate_hertz,json=sampleRateHertz,proto3" json:"sample_rate_hertz,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *RawAudio) Reset() {
	*x = RawAudio{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RawAudio) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RawAudio) ProtoMessage() {}

func (x *RawAudio) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RawAudio.ProtoReflect.Descriptor instead.
func (*RawAudio) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{2}
}

func (x *RawAudio) GetAudioEncoding() RawAudio_AudioEncoding {
	if x != nil {
		return x.AudioEncoding
	}
	return RawAudio_AUDIO_ENCODING_UNSPECIFIED
}

func (x *RawAudio) GetSampleRateHertz() int64 {
	if x != nil {
		return x.SampleRateHertz
	}
	return 0
}

type ContainerAudio struct {
	state              protoimpl.MessageState            `protogen:"open.v1"`
	ContainerAudioType ContainerAudio_ContainerAudioType `protobuf:"varint,1,opt,name=container_audio_type,json=containerAudioType,proto3,enum=speechkit.tts.v3.ContainerAudio_ContainerAudioType" json:"container_audio_type,omitempty"`
	unknownFields      protoimpl.UnknownFields
	sizeCache          protoimpl.SizeCache
}

func (x *ContainerAudio) Reset() {
	*x = ContainerAudio{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ContainerAudio) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ContainerAudio) ProtoMessage() {}

func (x *ContainerAudio) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ContainerAudio.ProtoReflect.Descriptor instead.
func (*ContainerAudio) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{3}
}

func (x *ContainerAudio) GetContainerAudioType() ContainerAudio_ContainerAudioType {
	if x != nil {
		return x.ContainerAudioType
	}
	return ContainerAudio_CONTAINER_AUDIO_TYPE_UNSPECIFIED
}

type TextVariable struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The name of the variable.
	VariableName string `protobuf:"bytes,1,opt,name=variable_name,json=variableName,proto3" json:"variable_name,omitempty"`
	// The text of the variable.
	VariableValue string `protobuf:"bytes,2,opt,name=variable_value,json=variableValue,proto3" json:"variable_value,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TextVariable) Reset() {
	*x = TextVariable{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TextVariable) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TextVariable) ProtoMessage() {}

func (x *TextVariable) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TextVariable.ProtoReflect.Descriptor instead.
func (*TextVariable) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{4}
}

func (x *TextVariable) GetVariableName() string {
	if x != nil {
		return x.VariableName
	}
	return ""
}

func (x *TextVariable) GetVariableValue() string {
	if x != nil {
		return x.VariableValue
	}
	return ""
}

type AudioVariable struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The name of the variable.
	VariableName string `protobuf:"bytes,1,opt,name=variable_name,json=variableName,proto3" json:"variable_name,omitempty"`
	// Start time of the variable in milliseconds.
	VariableStartMs int64 `protobuf:"varint,2,opt,name=variable_start_ms,json=variableStartMs,proto3" json:"variable_start_ms,omitempty"`
	// Length of the variable in milliseconds.
	VariableLengthMs int64 `protobuf:"varint,3,opt,name=variable_length_ms,json=variableLengthMs,proto3" json:"variable_length_ms,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *AudioVariable) Reset() {
	*x = AudioVariable{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AudioVariable) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AudioVariable) ProtoMessage() {}

func (x *AudioVariable) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AudioVariable.ProtoReflect.Descriptor instead.
func (*AudioVariable) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{5}
}

func (x *AudioVariable) GetVariableName() string {
	if x != nil {
		return x.VariableName
	}
	return ""
}

func (x *AudioVariable) GetVariableStartMs() int64 {
	if x != nil {
		return x.VariableStartMs
	}
	return 0
}

func (x *AudioVariable) GetVariableLengthMs() int64 {
	if x != nil {
		return x.VariableLengthMs
	}
	return 0
}

type UtteranceSynthesisResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Part of synthesized audio.
	AudioChunk *AudioChunk `protobuf:"bytes,1,opt,name=audio_chunk,json=audioChunk,proto3" json:"audio_chunk,omitempty"`
	// Part of synthesized text.
	TextChunk *TextChunk `protobuf:"bytes,2,opt,name=text_chunk,json=textChunk,proto3" json:"text_chunk,omitempty"`
	// Start time of the audio chunk in milliseconds.
	StartMs int64 `protobuf:"varint,3,opt,name=start_ms,json=startMs,proto3" json:"start_ms,omitempty"`
	// Length of the audio chunk in milliseconds.
	LengthMs      int64 `protobuf:"varint,4,opt,name=length_ms,json=lengthMs,proto3" json:"length_ms,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UtteranceSynthesisResponse) Reset() {
	*x = UtteranceSynthesisResponse{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UtteranceSynthesisResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UtteranceSynthesisResponse) ProtoMessage() {}

func (x *UtteranceSynthesisResponse) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UtteranceSynthesisResponse.ProtoReflect.Descriptor instead.
func (*UtteranceSynthesisResponse) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{6}
}

func (x *UtteranceSynthesisResponse) GetAudioChunk() *AudioChunk {
	if x != nil {
		return x.AudioChunk
	}
	return nil
}

func (x *UtteranceSynthesisResponse) GetTextChunk() *TextChunk {
	if x != nil {
		return x.TextChunk
	}
	return nil
}

func (x *UtteranceSynthesisResponse) GetStartMs() int64 {
	if x != nil {
		return x.StartMs
	}
	return 0
}

func (x *UtteranceSynthesisResponse) GetLengthMs() int64 {
	if x != nil {
		return x.LengthMs
	}
	return 0
}

type AudioTemplate struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Audio file.
	Audio *AudioContent `protobuf:"bytes,1,opt,name=audio,proto3" json:"audio,omitempty"`
	// Template and description of its variables.
	TextTemplate *TextTemplate `protobuf:"bytes,2,opt,name=text_template,json=textTemplate,proto3" json:"text_template,omitempty"`
	// Describing variables in audio.
	Variables     []*AudioVariable `protobuf:"bytes,3,rep,name=variables,proto3" json:"variables,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AudioTemplate) Reset() {
	*x = AudioTemplate{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AudioTemplate) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AudioTemplate) ProtoMessage() {}

func (x *AudioTemplate) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AudioTemplate.ProtoReflect.Descriptor instead.
func (*AudioTemplate) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{7}
}

func (x *AudioTemplate) GetAudio() *AudioContent {
	if x != nil {
		return x.Audio
	}
	return nil
}

func (x *AudioTemplate) GetTextTemplate() *TextTemplate {
	if x != nil {
		return x.TextTemplate
	}
	return nil
}

func (x *AudioTemplate) GetVariables() []*AudioVariable {
	if x != nil {
		return x.Variables
	}
	return nil
}

type AudioChunk struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Sequence of bytes of the synthesized audio in format specified in output_audio_spec.
	Data          []byte `protobuf:"bytes,1,opt,name=data,proto3" json:"data,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AudioChunk) Reset() {
	*x = AudioChunk{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AudioChunk) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AudioChunk) ProtoMessage() {}

func (x *AudioChunk) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AudioChunk.ProtoReflect.Descriptor instead.
func (*AudioChunk) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{8}
}

func (x *AudioChunk) GetData() []byte {
	if x != nil {
		return x.Data
	}
	return nil
}

type TextChunk struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Synthesized text.
	Text          string `protobuf:"bytes,1,opt,name=text,proto3" json:"text,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TextChunk) Reset() {
	*x = TextChunk{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TextChunk) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TextChunk) ProtoMessage() {}

func (x *TextChunk) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TextChunk.ProtoReflect.Descriptor instead.
func (*TextChunk) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{9}
}

func (x *TextChunk) GetText() string {
	if x != nil {
		return x.Text
	}
	return ""
}

type TextTemplate struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Template text.
	//
	// Sample:`The {animal} goes to the {place}.`
	TextTemplate string `protobuf:"bytes,1,opt,name=text_template,json=textTemplate,proto3" json:"text_template,omitempty"`
	// Defining variables in template text.
	//
	// Sample: `{animal: cat, place: forest}`
	Variables     []*TextVariable `protobuf:"bytes,2,rep,name=variables,proto3" json:"variables,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TextTemplate) Reset() {
	*x = TextTemplate{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TextTemplate) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TextTemplate) ProtoMessage() {}

func (x *TextTemplate) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TextTemplate.ProtoReflect.Descriptor instead.
func (*TextTemplate) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{10}
}

func (x *TextTemplate) GetTextTemplate() string {
	if x != nil {
		return x.TextTemplate
	}
	return ""
}

func (x *TextTemplate) GetVariables() []*TextVariable {
	if x != nil {
		return x.Variables
	}
	return nil
}

type DurationHint struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Type of duration constraint.
	Policy DurationHint_DurationHintPolicy `protobuf:"varint,1,opt,name=policy,proto3,enum=speechkit.tts.v3.DurationHint_DurationHintPolicy" json:"policy,omitempty"`
	// Constraint on audio duration in milliseconds.
	DurationMs    int64 `protobuf:"varint,2,opt,name=duration_ms,json=durationMs,proto3" json:"duration_ms,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DurationHint) Reset() {
	*x = DurationHint{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DurationHint) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DurationHint) ProtoMessage() {}

func (x *DurationHint) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DurationHint.ProtoReflect.Descriptor instead.
func (*DurationHint) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{11}
}

func (x *DurationHint) GetPolicy() DurationHint_DurationHintPolicy {
	if x != nil {
		return x.Policy
	}
	return DurationHint_DURATION_HINT_POLICY_UNSPECIFIED
}

func (x *DurationHint) GetDurationMs() int64 {
	if x != nil {
		return x.DurationMs
	}
	return 0
}

type Hints struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The hint for TTS engine to specify synthesised audio characteristics.
	//
	// Types that are valid to be assigned to Hint:
	//
	//	*Hints_Voice
	//	*Hints_AudioTemplate
	//	*Hints_Speed
	//	*Hints_Volume
	//	*Hints_Role
	//	*Hints_PitchShift
	//	*Hints_Duration
	Hint          isHints_Hint `protobuf_oneof:"Hint"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Hints) Reset() {
	*x = Hints{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Hints) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Hints) ProtoMessage() {}

func (x *Hints) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Hints.ProtoReflect.Descriptor instead.
func (*Hints) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{12}
}

func (x *Hints) GetHint() isHints_Hint {
	if x != nil {
		return x.Hint
	}
	return nil
}

func (x *Hints) GetVoice() string {
	if x != nil {
		if x, ok := x.Hint.(*Hints_Voice); ok {
			return x.Voice
		}
	}
	return ""
}

func (x *Hints) GetAudioTemplate() *AudioTemplate {
	if x != nil {
		if x, ok := x.Hint.(*Hints_AudioTemplate); ok {
			return x.AudioTemplate
		}
	}
	return nil
}

func (x *Hints) GetSpeed() float64 {
	if x != nil {
		if x, ok := x.Hint.(*Hints_Speed); ok {
			return x.Speed
		}
	}
	return 0
}

func (x *Hints) GetVolume() float64 {
	if x != nil {
		if x, ok := x.Hint.(*Hints_Volume); ok {
			return x.Volume
		}
	}
	return 0
}

func (x *Hints) GetRole() string {
	if x != nil {
		if x, ok := x.Hint.(*Hints_Role); ok {
			return x.Role
		}
	}
	return ""
}

func (x *Hints) GetPitchShift() float64 {
	if x != nil {
		if x, ok := x.Hint.(*Hints_PitchShift); ok {
			return x.PitchShift
		}
	}
	return 0
}

func (x *Hints) GetDuration() *DurationHint {
	if x != nil {
		if x, ok := x.Hint.(*Hints_Duration); ok {
			return x.Duration
		}
	}
	return nil
}

type isHints_Hint interface {
	isHints_Hint()
}

type Hints_Voice struct {
	// Name of speaker to use.
	Voice string `protobuf:"bytes,1,opt,name=voice,proto3,oneof"`
}

type Hints_AudioTemplate struct {
	// Template for synthesizing.
	AudioTemplate *AudioTemplate `protobuf:"bytes,2,opt,name=audio_template,json=audioTemplate,proto3,oneof"`
}

type Hints_Speed struct {
	// Hint to change speed.
	Speed float64 `protobuf:"fixed64,3,opt,name=speed,proto3,oneof"`
}

type Hints_Volume struct {
	// Hint to regulate normalization level.
	// * For `MAX_PEAK` loudness_normalization_type: volume changes in a range (0;1], default value is 0.7.
	// * For `LUFS` loudness_normalization_type: volume changes in a range [-145;0), default value is -19.
	Volume float64 `protobuf:"fixed64,4,opt,name=volume,proto3,oneof"`
}

type Hints_Role struct {
	// Hint to specify pronunciation character for the speaker.
	Role string `protobuf:"bytes,5,opt,name=role,proto3,oneof"`
}

type Hints_PitchShift struct {
	// Hint to increase (or decrease) speaker's pitch, measured in Hz. Valid values are in range [-1000;1000], default value is 0.
	PitchShift float64 `protobuf:"fixed64,6,opt,name=pitch_shift,json=pitchShift,proto3,oneof"`
}

type Hints_Duration struct {
	// Hint to limit both minimum and maximum audio duration.
	Duration *DurationHint `protobuf:"bytes,7,opt,name=duration,proto3,oneof"`
}

func (*Hints_Voice) isHints_Hint() {}

func (*Hints_AudioTemplate) isHints_Hint() {}

func (*Hints_Speed) isHints_Hint() {}

func (*Hints_Volume) isHints_Hint() {}

func (*Hints_Role) isHints_Hint() {}

func (*Hints_PitchShift) isHints_Hint() {}

func (*Hints_Duration) isHints_Hint() {}

type UtteranceSynthesisRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The name of the model.
	// This parameter is only required for specific functionalities, such as [SpeechKit Brand Voice Lite](/docs/speechkit/tts/brand-voice/) or SpeechKit Brand Voice Call Center. If you are not sure whether your use case needs this parameter, do not include it.
	Model string `protobuf:"bytes,1,opt,name=model,proto3" json:"model,omitempty"`
	// Text to synthesis, one of text synthesis markups.
	//
	// Types that are valid to be assigned to Utterance:
	//
	//	*UtteranceSynthesisRequest_Text
	//	*UtteranceSynthesisRequest_TextTemplate
	Utterance isUtteranceSynthesisRequest_Utterance `protobuf_oneof:"Utterance"`
	// Optional hints for synthesis.
	Hints []*Hints `protobuf:"bytes,4,rep,name=hints,proto3" json:"hints,omitempty"`
	// Optional. Default: 22050 Hz, linear 16-bit signed little-endian PCM, with WAV header
	OutputAudioSpec *AudioFormatOptions `protobuf:"bytes,5,opt,name=output_audio_spec,json=outputAudioSpec,proto3" json:"output_audio_spec,omitempty"`
	// Specifies type of loudness normalization.
	// Optional. Default: `LUFS`.
	LoudnessNormalizationType UtteranceSynthesisRequest_LoudnessNormalizationType `protobuf:"varint,6,opt,name=loudness_normalization_type,json=loudnessNormalizationType,proto3,enum=speechkit.tts.v3.UtteranceSynthesisRequest_LoudnessNormalizationType" json:"loudness_normalization_type,omitempty"`
	// Optional. Automatically split long text to several utterances and bill accordingly. Some degradation in service quality is possible.
	UnsafeMode    bool `protobuf:"varint,7,opt,name=unsafe_mode,json=unsafeMode,proto3" json:"unsafe_mode,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UtteranceSynthesisRequest) Reset() {
	*x = UtteranceSynthesisRequest{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UtteranceSynthesisRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UtteranceSynthesisRequest) ProtoMessage() {}

func (x *UtteranceSynthesisRequest) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UtteranceSynthesisRequest.ProtoReflect.Descriptor instead.
func (*UtteranceSynthesisRequest) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{13}
}

func (x *UtteranceSynthesisRequest) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *UtteranceSynthesisRequest) GetUtterance() isUtteranceSynthesisRequest_Utterance {
	if x != nil {
		return x.Utterance
	}
	return nil
}

func (x *UtteranceSynthesisRequest) GetText() string {
	if x != nil {
		if x, ok := x.Utterance.(*UtteranceSynthesisRequest_Text); ok {
			return x.Text
		}
	}
	return ""
}

func (x *UtteranceSynthesisRequest) GetTextTemplate() *TextTemplate {
	if x != nil {
		if x, ok := x.Utterance.(*UtteranceSynthesisRequest_TextTemplate); ok {
			return x.TextTemplate
		}
	}
	return nil
}

func (x *UtteranceSynthesisRequest) GetHints() []*Hints {
	if x != nil {
		return x.Hints
	}
	return nil
}

func (x *UtteranceSynthesisRequest) GetOutputAudioSpec() *AudioFormatOptions {
	if x != nil {
		return x.OutputAudioSpec
	}
	return nil
}

func (x *UtteranceSynthesisRequest) GetLoudnessNormalizationType() UtteranceSynthesisRequest_LoudnessNormalizationType {
	if x != nil {
		return x.LoudnessNormalizationType
	}
	return UtteranceSynthesisRequest_LOUDNESS_NORMALIZATION_TYPE_UNSPECIFIED
}

func (x *UtteranceSynthesisRequest) GetUnsafeMode() bool {
	if x != nil {
		return x.UnsafeMode
	}
	return false
}

type isUtteranceSynthesisRequest_Utterance interface {
	isUtteranceSynthesisRequest_Utterance()
}

type UtteranceSynthesisRequest_Text struct {
	// Raw text (e.g. "Hello, Alice").
	Text string `protobuf:"bytes,2,opt,name=text,proto3,oneof"`
}

type UtteranceSynthesisRequest_TextTemplate struct {
	// Text template instance, e.g. `{"Hello, {username}" with username="Alice"}`.
	TextTemplate *TextTemplate `protobuf:"bytes,3,opt,name=text_template,json=textTemplate,proto3,oneof"`
}

func (*UtteranceSynthesisRequest_Text) isUtteranceSynthesisRequest_Utterance() {}

func (*UtteranceSynthesisRequest_TextTemplate) isUtteranceSynthesisRequest_Utterance() {}

type SynthesisOptions struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The name of the TTS model to use for synthesis. Currently should be empty. Do not use it.
	Model string `protobuf:"bytes,1,opt,name=model,proto3" json:"model,omitempty"`
	// The voice to use for speech synthesis.
	Voice string `protobuf:"bytes,2,opt,name=voice,proto3" json:"voice,omitempty"`
	// The role or speaking style. Can be used to specify pronunciation character for the speaker.
	Role string `protobuf:"bytes,3,opt,name=role,proto3" json:"role,omitempty"`
	// Speed multiplier (default: 1.0).
	Speed float64 `protobuf:"fixed64,4,opt,name=speed,proto3" json:"speed,omitempty"`
	// Volume adjustment:
	// * For `MAX_PEAK`: range is (0, 1], default 0.7.
	// * For `LUFS`: range is [-145, 0), default -19.
	Volume float64 `protobuf:"fixed64,5,opt,name=volume,proto3" json:"volume,omitempty"`
	// Pitch adjustment, in Hz, range [-1000, 1000], default 0.
	PitchShift float64 `protobuf:"fixed64,6,opt,name=pitch_shift,json=pitchShift,proto3" json:"pitch_shift,omitempty"`
	// Specifies output audio format. Default: 22050Hz, linear 16-bit signed little-endian PCM, with WAV header.
	OutputAudioSpec *AudioFormatOptions `protobuf:"bytes,7,opt,name=output_audio_spec,json=outputAudioSpec,proto3" json:"output_audio_spec,omitempty"`
	// Loudness normalization type for output (default: `LUFS`).
	LoudnessNormalizationType LoudnessNormalizationType `protobuf:"varint,8,opt,name=loudness_normalization_type,json=loudnessNormalizationType,proto3,enum=speechkit.tts.v3.LoudnessNormalizationType" json:"loudness_normalization_type,omitempty"`
	unknownFields             protoimpl.UnknownFields
	sizeCache                 protoimpl.SizeCache
}

func (x *SynthesisOptions) Reset() {
	*x = SynthesisOptions{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SynthesisOptions) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SynthesisOptions) ProtoMessage() {}

func (x *SynthesisOptions) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SynthesisOptions.ProtoReflect.Descriptor instead.
func (*SynthesisOptions) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{14}
}

func (x *SynthesisOptions) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *SynthesisOptions) GetVoice() string {
	if x != nil {
		return x.Voice
	}
	return ""
}

func (x *SynthesisOptions) GetRole() string {
	if x != nil {
		return x.Role
	}
	return ""
}

func (x *SynthesisOptions) GetSpeed() float64 {
	if x != nil {
		return x.Speed
	}
	return 0
}

func (x *SynthesisOptions) GetVolume() float64 {
	if x != nil {
		return x.Volume
	}
	return 0
}

func (x *SynthesisOptions) GetPitchShift() float64 {
	if x != nil {
		return x.PitchShift
	}
	return 0
}

func (x *SynthesisOptions) GetOutputAudioSpec() *AudioFormatOptions {
	if x != nil {
		return x.OutputAudioSpec
	}
	return nil
}

func (x *SynthesisOptions) GetLoudnessNormalizationType() LoudnessNormalizationType {
	if x != nil {
		return x.LoudnessNormalizationType
	}
	return LoudnessNormalizationType_LOUDNESS_NORMALIZATION_TYPE_UNSPECIFIED
}

// The input for synthesis.
type SynthesisInput struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The text string to be synthesized.
	Text          string `protobuf:"bytes,1,opt,name=text,proto3" json:"text,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SynthesisInput) Reset() {
	*x = SynthesisInput{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SynthesisInput) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SynthesisInput) ProtoMessage() {}

func (x *SynthesisInput) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SynthesisInput.ProtoReflect.Descriptor instead.
func (*SynthesisInput) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{15}
}

func (x *SynthesisInput) GetText() string {
	if x != nil {
		return x.Text
	}
	return ""
}

// Event to forcibly trigger synthesis.
type ForceSynthesisEvent struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ForceSynthesisEvent) Reset() {
	*x = ForceSynthesisEvent{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[16]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ForceSynthesisEvent) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ForceSynthesisEvent) ProtoMessage() {}

func (x *ForceSynthesisEvent) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[16]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ForceSynthesisEvent.ProtoReflect.Descriptor instead.
func (*ForceSynthesisEvent) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{16}
}

// Sent by client to control or provide data during streaming synthesis.
type StreamSynthesisRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Event:
	//
	//	*StreamSynthesisRequest_Options
	//	*StreamSynthesisRequest_SynthesisInput
	//	*StreamSynthesisRequest_ForceSynthesis
	Event         isStreamSynthesisRequest_Event `protobuf_oneof:"Event"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StreamSynthesisRequest) Reset() {
	*x = StreamSynthesisRequest{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[17]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StreamSynthesisRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamSynthesisRequest) ProtoMessage() {}

func (x *StreamSynthesisRequest) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[17]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamSynthesisRequest.ProtoReflect.Descriptor instead.
func (*StreamSynthesisRequest) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{17}
}

func (x *StreamSynthesisRequest) GetEvent() isStreamSynthesisRequest_Event {
	if x != nil {
		return x.Event
	}
	return nil
}

func (x *StreamSynthesisRequest) GetOptions() *SynthesisOptions {
	if x != nil {
		if x, ok := x.Event.(*StreamSynthesisRequest_Options); ok {
			return x.Options
		}
	}
	return nil
}

func (x *StreamSynthesisRequest) GetSynthesisInput() *SynthesisInput {
	if x != nil {
		if x, ok := x.Event.(*StreamSynthesisRequest_SynthesisInput); ok {
			return x.SynthesisInput
		}
	}
	return nil
}

func (x *StreamSynthesisRequest) GetForceSynthesis() *ForceSynthesisEvent {
	if x != nil {
		if x, ok := x.Event.(*StreamSynthesisRequest_ForceSynthesis); ok {
			return x.ForceSynthesis
		}
	}
	return nil
}

type isStreamSynthesisRequest_Event interface {
	isStreamSynthesisRequest_Event()
}

type StreamSynthesisRequest_Options struct {
	// Synthesis options. Must be provided in the first request of the stream and cannot be updated afterwards.
	Options *SynthesisOptions `protobuf:"bytes,1,opt,name=options,proto3,oneof"`
}

type StreamSynthesisRequest_SynthesisInput struct {
	// Input to be synthesized.
	SynthesisInput *SynthesisInput `protobuf:"bytes,2,opt,name=synthesis_input,json=synthesisInput,proto3,oneof"`
}

type StreamSynthesisRequest_ForceSynthesis struct {
	// Triggers immediate synthesis of buffered input.
	ForceSynthesis *ForceSynthesisEvent `protobuf:"bytes,3,opt,name=force_synthesis,json=forceSynthesis,proto3,oneof"`
}

func (*StreamSynthesisRequest_Options) isStreamSynthesisRequest_Event() {}

func (*StreamSynthesisRequest_SynthesisInput) isStreamSynthesisRequest_Event() {}

func (*StreamSynthesisRequest_ForceSynthesis) isStreamSynthesisRequest_Event() {}

type StreamSynthesisResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Part of synthesized audio.
	AudioChunk *AudioChunk `protobuf:"bytes,1,opt,name=audio_chunk,json=audioChunk,proto3" json:"audio_chunk,omitempty"`
	// Part of synthesized text.
	TextChunk *TextChunk `protobuf:"bytes,2,opt,name=text_chunk,json=textChunk,proto3" json:"text_chunk,omitempty"`
	// Start time of the audio chunk in milliseconds.
	StartMs int64 `protobuf:"varint,3,opt,name=start_ms,json=startMs,proto3" json:"start_ms,omitempty"`
	// Length of the audio chunk in milliseconds.
	LengthMs      int64 `protobuf:"varint,4,opt,name=length_ms,json=lengthMs,proto3" json:"length_ms,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StreamSynthesisResponse) Reset() {
	*x = StreamSynthesisResponse{}
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[18]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StreamSynthesisResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamSynthesisResponse) ProtoMessage() {}

func (x *StreamSynthesisResponse) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[18]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamSynthesisResponse.ProtoReflect.Descriptor instead.
func (*StreamSynthesisResponse) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP(), []int{18}
}

func (x *StreamSynthesisResponse) GetAudioChunk() *AudioChunk {
	if x != nil {
		return x.AudioChunk
	}
	return nil
}

func (x *StreamSynthesisResponse) GetTextChunk() *TextChunk {
	if x != nil {
		return x.TextChunk
	}
	return nil
}

func (x *StreamSynthesisResponse) GetStartMs() int64 {
	if x != nil {
		return x.StartMs
	}
	return 0
}

func (x *StreamSynthesisResponse) GetLengthMs() int64 {
	if x != nil {
		return x.LengthMs
	}
	return 0
}

var File_yandex_cloud_ai_tts_v3_tts_proto protoreflect.FileDescriptor

const file_yandex_cloud_ai_tts_v3_tts_proto_rawDesc = "" +
	"\n" +
	" yandex/cloud/ai/tts/v3/tts.proto\x12\x10speechkit.tts.v3\"~\n" +
	"\fAudioContent\x12\x1a\n" +
	"\acontent\x18\x01 \x01(\fH\x00R\acontent\x12C\n" +
	"\n" +
	"audio_spec\x18\x02 \x01(\v2$.speechkit.tts.v3.AudioFormatOptionsR\taudioSpecB\r\n" +
	"\vAudioSource\"\xab\x01\n" +
	"\x12AudioFormatOptions\x129\n" +
	"\traw_audio\x18\x01 \x01(\v2\x1a.speechkit.tts.v3.RawAudioH\x00R\brawAudio\x12K\n" +
	"\x0fcontainer_audio\x18\x02 \x01(\v2 .speechkit.tts.v3.ContainerAudioH\x00R\x0econtainerAudioB\r\n" +
	"\vAudioFormat\"\xca\x01\n" +
	"\bRawAudio\x12O\n" +
	"\x0eaudio_encoding\x18\x01 \x01(\x0e2(.speechkit.tts.v3.RawAudio.AudioEncodingR\raudioEncoding\x12*\n" +
	"\x11sample_rate_hertz\x18\x02 \x01(\x03R\x0fsampleRateHertz\"A\n" +
	"\rAudioEncoding\x12\x1e\n" +
	"\x1aAUDIO_ENCODING_UNSPECIFIED\x10\x00\x12\x10\n" +
	"\fLINEAR16_PCM\x10\x01\"\xd3\x01\n" +
	"\x0eContainerAudio\x12e\n" +
	"\x14container_audio_type\x18\x01 \x01(\x0e23.speechkit.tts.v3.ContainerAudio.ContainerAudioTypeR\x12containerAudioType\"Z\n" +
	"\x12ContainerAudioType\x12$\n" +
	" CONTAINER_AUDIO_TYPE_UNSPECIFIED\x10\x00\x12\a\n" +
	"\x03WAV\x10\x01\x12\f\n" +
	"\bOGG_OPUS\x10\x02\x12\a\n" +
	"\x03MP3\x10\x03\"Z\n" +
	"\fTextVariable\x12#\n" +
	"\rvariable_name\x18\x01 \x01(\tR\fvariableName\x12%\n" +
	"\x0evariable_value\x18\x02 \x01(\tR\rvariableValue\"\x8e\x01\n" +
	"\rAudioVariable\x12#\n" +
	"\rvariable_name\x18\x01 \x01(\tR\fvariableName\x12*\n" +
	"\x11variable_start_ms\x18\x02 \x01(\x03R\x0fvariableStartMs\x12,\n" +
	"\x12variable_length_ms\x18\x03 \x01(\x03R\x10variableLengthMs\"\xcf\x01\n" +
	"\x1aUtteranceSynthesisResponse\x12=\n" +
	"\vaudio_chunk\x18\x01 \x01(\v2\x1c.speechkit.tts.v3.AudioChunkR\n" +
	"audioChunk\x12:\n" +
	"\n" +
	"text_chunk\x18\x02 \x01(\v2\x1b.speechkit.tts.v3.TextChunkR\ttextChunk\x12\x19\n" +
	"\bstart_ms\x18\x03 \x01(\x03R\astartMs\x12\x1b\n" +
	"\tlength_ms\x18\x04 \x01(\x03R\blengthMs\"\xc9\x01\n" +
	"\rAudioTemplate\x124\n" +
	"\x05audio\x18\x01 \x01(\v2\x1e.speechkit.tts.v3.AudioContentR\x05audio\x12C\n" +
	"\rtext_template\x18\x02 \x01(\v2\x1e.speechkit.tts.v3.TextTemplateR\ftextTemplate\x12=\n" +
	"\tvariables\x18\x03 \x03(\v2\x1f.speechkit.tts.v3.AudioVariableR\tvariables\" \n" +
	"\n" +
	"AudioChunk\x12\x12\n" +
	"\x04data\x18\x01 \x01(\fR\x04data\"\x1f\n" +
	"\tTextChunk\x12\x12\n" +
	"\x04text\x18\x01 \x01(\tR\x04text\"q\n" +
	"\fTextTemplate\x12#\n" +
	"\rtext_template\x18\x01 \x01(\tR\ftextTemplate\x12<\n" +
	"\tvariables\x18\x02 \x03(\v2\x1e.speechkit.tts.v3.TextVariableR\tvariables\"\xee\x01\n" +
	"\fDurationHint\x12I\n" +
	"\x06policy\x18\x01 \x01(\x0e21.speechkit.tts.v3.DurationHint.DurationHintPolicyR\x06policy\x12\x1f\n" +
	"\vduration_ms\x18\x02 \x01(\x03R\n" +
	"durationMs\"r\n" +
	"\x12DurationHintPolicy\x12$\n" +
	" DURATION_HINT_POLICY_UNSPECIFIED\x10\x00\x12\x12\n" +
	"\x0eEXACT_DURATION\x10\x01\x12\x10\n" +
	"\fMIN_DURATION\x10\x02\x12\x10\n" +
	"\fMAX_DURATION\x10\x03\"\x9a\x02\n" +
	"\x05Hints\x12\x16\n" +
	"\x05voice\x18\x01 \x01(\tH\x00R\x05voice\x12H\n" +
	"\x0eaudio_template\x18\x02 \x01(\v2\x1f.speechkit.tts.v3.AudioTemplateH\x00R\raudioTemplate\x12\x16\n" +
	"\x05speed\x18\x03 \x01(\x01H\x00R\x05speed\x12\x18\n" +
	"\x06volume\x18\x04 \x01(\x01H\x00R\x06volume\x12\x14\n" +
	"\x04role\x18\x05 \x01(\tH\x00R\x04role\x12!\n" +
	"\vpitch_shift\x18\x06 \x01(\x01H\x00R\n" +
	"pitchShift\x12<\n" +
	"\bduration\x18\a \x01(\v2\x1e.speechkit.tts.v3.DurationHintH\x00R\bdurationB\x06\n" +
	"\x04Hint\"\xa7\x04\n" +
	"\x19UtteranceSynthesisRequest\x12\x14\n" +
	"\x05model\x18\x01 \x01(\tR\x05model\x12\x14\n" +
	"\x04text\x18\x02 \x01(\tH\x00R\x04text\x12E\n" +
	"\rtext_template\x18\x03 \x01(\v2\x1e.speechkit.tts.v3.TextTemplateH\x00R\ftextTemplate\x12-\n" +
	"\x05hints\x18\x04 \x03(\v2\x17.speechkit.tts.v3.HintsR\x05hints\x12P\n" +
	"\x11output_audio_spec\x18\x05 \x01(\v2$.speechkit.tts.v3.AudioFormatOptionsR\x0foutputAudioSpec\x12\x85\x01\n" +
	"\x1bloudness_normalization_type\x18\x06 \x01(\x0e2E.speechkit.tts.v3.UtteranceSynthesisRequest.LoudnessNormalizationTypeR\x19loudnessNormalizationType\x12\x1f\n" +
	"\vunsafe_mode\x18\a \x01(\bR\n" +
	"unsafeMode\"`\n" +
	"\x19LoudnessNormalizationType\x12+\n" +
	"'LOUDNESS_NORMALIZATION_TYPE_UNSPECIFIED\x10\x00\x12\f\n" +
	"\bMAX_PEAK\x10\x01\x12\b\n" +
	"\x04LUFS\x10\x02B\v\n" +
	"\tUtterance\"\xe0\x02\n" +
	"\x10SynthesisOptions\x12\x14\n" +
	"\x05model\x18\x01 \x01(\tR\x05model\x12\x14\n" +
	"\x05voice\x18\x02 \x01(\tR\x05voice\x12\x12\n" +
	"\x04role\x18\x03 \x01(\tR\x04role\x12\x14\n" +
	"\x05speed\x18\x04 \x01(\x01R\x05speed\x12\x16\n" +
	"\x06volume\x18\x05 \x01(\x01R\x06volume\x12\x1f\n" +
	"\vpitch_shift\x18\x06 \x01(\x01R\n" +
	"pitchShift\x12P\n" +
	"\x11output_audio_spec\x18\a \x01(\v2$.speechkit.tts.v3.AudioFormatOptionsR\x0foutputAudioSpec\x12k\n" +
	"\x1bloudness_normalization_type\x18\b \x01(\x0e2+.speechkit.tts.v3.LoudnessNormalizationTypeR\x19loudnessNormalizationType\"$\n" +
	"\x0eSynthesisInput\x12\x12\n" +
	"\x04text\x18\x01 \x01(\tR\x04text\"\x15\n" +
	"\x13ForceSynthesisEvent\"\x80\x02\n" +
	"\x16StreamSynthesisRequest\x12>\n" +
	"\aoptions\x18\x01 \x01(\v2\".speechkit.tts.v3.SynthesisOptionsH\x00R\aoptions\x12K\n" +
	"\x0fsynthesis_input\x18\x02 \x01(\v2 .speechkit.tts.v3.SynthesisInputH\x00R\x0esynthesisInput\x12P\n" +
	"\x0fforce_synthesis\x18\x03 \x01(\v2%.speechkit.tts.v3.ForceSynthesisEventH\x00R\x0eforceSynthesisB\a\n" +
	"\x05Event\"\xcc\x01\n" +
	"\x17StreamSynthesisResponse\x12=\n" +
	"\vaudio_chunk\x18\x01 \x01(\v2\x1c.speechkit.tts.v3.AudioChunkR\n" +
	"audioChunk\x12:\n" +
	"\n" +
	"text_chunk\x18\x02 \x01(\v2\x1b.speechkit.tts.v3.TextChunkR\ttextChunk\x12\x19\n" +
	"\bstart_ms\x18\x03 \x01(\x03R\astartMs\x12\x1b\n" +
	"\tlength_ms\x18\x04 \x01(\x03R\blengthMs*`\n" +
	"\x19LoudnessNormalizationType\x12+\n" +
	"'LOUDNESS_NORMALIZATION_TYPE_UNSPECIFIED\x10\x00\x12\f\n" +
	"\bMAX_PEAK\x10\x01\x12\b\n" +
	"\x04LUFS\x10\x02B\\\n" +
	"\x1ayandex.cloud.api.ai.tts.v3Z>github.com/yandex-cloud/go-genproto/yandex/cloud/ai/tts/v3;ttsb\x06proto3"

var (
	file_yandex_cloud_ai_tts_v3_tts_proto_rawDescOnce sync.Once
	file_yandex_cloud_ai_tts_v3_tts_proto_rawDescData []byte
)

func file_yandex_cloud_ai_tts_v3_tts_proto_rawDescGZIP() []byte {
	file_yandex_cloud_ai_tts_v3_tts_proto_rawDescOnce.Do(func() {
		file_yandex_cloud_ai_tts_v3_tts_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_yandex_cloud_ai_tts_v3_tts_proto_rawDesc), len(file_yandex_cloud_ai_tts_v3_tts_proto_rawDesc)))
	})
	return file_yandex_cloud_ai_tts_v3_tts_proto_rawDescData
}

var file_yandex_cloud_ai_tts_v3_tts_proto_enumTypes = make([]protoimpl.EnumInfo, 5)
var file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes = make([]protoimpl.MessageInfo, 19)
var file_yandex_cloud_ai_tts_v3_tts_proto_goTypes = []any{
	(LoudnessNormalizationType)(0),                           // 0: speechkit.tts.v3.LoudnessNormalizationType
	(RawAudio_AudioEncoding)(0),                              // 1: speechkit.tts.v3.RawAudio.AudioEncoding
	(ContainerAudio_ContainerAudioType)(0),                   // 2: speechkit.tts.v3.ContainerAudio.ContainerAudioType
	(DurationHint_DurationHintPolicy)(0),                     // 3: speechkit.tts.v3.DurationHint.DurationHintPolicy
	(UtteranceSynthesisRequest_LoudnessNormalizationType)(0), // 4: speechkit.tts.v3.UtteranceSynthesisRequest.LoudnessNormalizationType
	(*AudioContent)(nil),                                     // 5: speechkit.tts.v3.AudioContent
	(*AudioFormatOptions)(nil),                               // 6: speechkit.tts.v3.AudioFormatOptions
	(*RawAudio)(nil),                                         // 7: speechkit.tts.v3.RawAudio
	(*ContainerAudio)(nil),                                   // 8: speechkit.tts.v3.ContainerAudio
	(*TextVariable)(nil),                                     // 9: speechkit.tts.v3.TextVariable
	(*AudioVariable)(nil),                                    // 10: speechkit.tts.v3.AudioVariable
	(*UtteranceSynthesisResponse)(nil),                       // 11: speechkit.tts.v3.UtteranceSynthesisResponse
	(*AudioTemplate)(nil),                                    // 12: speechkit.tts.v3.AudioTemplate
	(*AudioChunk)(nil),                                       // 13: speechkit.tts.v3.AudioChunk
	(*TextChunk)(nil),                                        // 14: speechkit.tts.v3.TextChunk
	(*TextTemplate)(nil),                                     // 15: speechkit.tts.v3.TextTemplate
	(*DurationHint)(nil),                                     // 16: speechkit.tts.v3.DurationHint
	(*Hints)(nil),                                            // 17: speechkit.tts.v3.Hints
	(*UtteranceSynthesisRequest)(nil),                        // 18: speechkit.tts.v3.UtteranceSynthesisRequest
	(*SynthesisOptions)(nil),                                 // 19: speechkit.tts.v3.SynthesisOptions
	(*SynthesisInput)(nil),                                   // 20: speechkit.tts.v3.SynthesisInput
	(*ForceSynthesisEvent)(nil),                              // 21: speechkit.tts.v3.ForceSynthesisEvent
	(*StreamSynthesisRequest)(nil),                           // 22: speechkit.tts.v3.StreamSynthesisRequest
	(*StreamSynthesisResponse)(nil),                          // 23: speechkit.tts.v3.StreamSynthesisResponse
}
var file_yandex_cloud_ai_tts_v3_tts_proto_depIdxs = []int32{
	6,  // 0: speechkit.tts.v3.AudioContent.audio_spec:type_name -> speechkit.tts.v3.AudioFormatOptions
	7,  // 1: speechkit.tts.v3.AudioFormatOptions.raw_audio:type_name -> speechkit.tts.v3.RawAudio
	8,  // 2: speechkit.tts.v3.AudioFormatOptions.container_audio:type_name -> speechkit.tts.v3.ContainerAudio
	1,  // 3: speechkit.tts.v3.RawAudio.audio_encoding:type_name -> speechkit.tts.v3.RawAudio.AudioEncoding
	2,  // 4: speechkit.tts.v3.ContainerAudio.container_audio_type:type_name -> speechkit.tts.v3.ContainerAudio.ContainerAudioType
	13, // 5: speechkit.tts.v3.UtteranceSynthesisResponse.audio_chunk:type_name -> speechkit.tts.v3.AudioChunk
	14, // 6: speechkit.tts.v3.UtteranceSynthesisResponse.text_chunk:type_name -> speechkit.tts.v3.TextChunk
	5,  // 7: speechkit.tts.v3.AudioTemplate.audio:type_name -> speechkit.tts.v3.AudioContent
	15, // 8: speechkit.tts.v3.AudioTemplate.text_template:type_name -> speechkit.tts.v3.TextTemplate
	10, // 9: speechkit.tts.v3.AudioTemplate.variables:type_name -> speechkit.tts.v3.AudioVariable
	9,  // 10: speechkit.tts.v3.TextTemplate.variables:type_name -> speechkit.tts.v3.TextVariable
	3,  // 11: speechkit.tts.v3.DurationHint.policy:type_name -> speechkit.tts.v3.DurationHint.DurationHintPolicy
	12, // 12: speechkit.tts.v3.Hints.audio_template:type_name -> speechkit.tts.v3.AudioTemplate
	16, // 13: speechkit.tts.v3.Hints.duration:type_name -> speechkit.tts.v3.DurationHint
	15, // 14: speechkit.tts.v3.UtteranceSynthesisRequest.text_template:type_name -> speechkit.tts.v3.TextTemplate
	17, // 15: speechkit.tts.v3.UtteranceSynthesisRequest.hints:type_name -> speechkit.tts.v3.Hints
	6,  // 16: speechkit.tts.v3.UtteranceSynthesisRequest.output_audio_spec:type_name -> speechkit.tts.v3.AudioFormatOptions
	4,  // 17: speechkit.tts.v3.UtteranceSynthesisRequest.loudness_normalization_type:type_name -> speechkit.tts.v3.UtteranceSynthesisRequest.LoudnessNormalizationType
	6,  // 18: speechkit.tts.v3.SynthesisOptions.output_audio_spec:type_name -> speechkit.tts.v3.AudioFormatOptions
	0,  // 19: speechkit.tts.v3.SynthesisOptions.loudness_normalization_type:type_name -> speechkit.tts.v3.LoudnessNormalizationType
	19, // 20: speechkit.tts.v3.StreamSynthesisRequest.options:type_name -> speechkit.tts.v3.SynthesisOptions
	20, // 21: speechkit.tts.v3.StreamSynthesisRequest.synthesis_input:type_name -> speechkit.tts.v3.SynthesisInput
	21, // 22: speechkit.tts.v3.StreamSynthesisRequest.force_synthesis:type_name -> speechkit.tts.v3.ForceSynthesisEvent
	13, // 23: speechkit.tts.v3.StreamSynthesisResponse.audio_chunk:type_name -> speechkit.tts.v3.AudioChunk
	14, // 24: speechkit.tts.v3.StreamSynthesisResponse.text_chunk:type_name -> speechkit.tts.v3.TextChunk
	25, // [25:25] is the sub-list for method output_type
	25, // [25:25] is the sub-list for method input_type
	25, // [25:25] is the sub-list for extension type_name
	25, // [25:25] is the sub-list for extension extendee
	0,  // [0:25] is the sub-list for field type_name
}

func init() { file_yandex_cloud_ai_tts_v3_tts_proto_init() }
func file_yandex_cloud_ai_tts_v3_tts_proto_init() {
	if File_yandex_cloud_ai_tts_v3_tts_proto != nil {
		return
	}
	file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[0].OneofWrappers = []any{
		(*AudioContent_Content)(nil),
	}
	file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[1].OneofWrappers = []any{
		(*AudioFormatOptions_RawAudio)(nil),
		(*AudioFormatOptions_ContainerAudio)(nil),
	}
	file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[12].OneofWrappers = []any{
		(*Hints_Voice)(nil),
		(*Hints_AudioTemplate)(nil),
		(*Hints_Speed)(nil),
		(*Hints_Volume)(nil),
		(*Hints_Role)(nil),
		(*Hints_PitchShift)(nil),
		(*Hints_Duration)(nil),
	}
	file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[13].OneofWrappers = []any{
		(*UtteranceSynthesisRequest_Text)(nil),
		(*UtteranceSynthesisRequest_TextTemplate)(nil),
	}
	file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes[17].OneofWrappers = []any{
		(*StreamSynthesisRequest_Options)(nil),
		(*StreamSynthesisRequest_SynthesisInput)(nil),
		(*StreamSynthesisRequest_ForceSynthesis)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_yandex_cloud_ai_tts_v3_tts_proto_rawDesc), len(file_yandex_cloud_ai_tts_v3_tts_proto_rawDesc)),
			NumEnums:      5,
			NumMessages:   19,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_yandex_cloud_ai_tts_v3_tts_proto_goTypes,
		DependencyIndexes: file_yandex_cloud_ai_tts_v3_tts_proto_depIdxs,
		EnumInfos:         file_yandex_cloud_ai_tts_v3_tts_proto_enumTypes,
		MessageInfos:      file_yandex_cloud_ai_tts_v3_tts_proto_msgTypes,
	}.Build()
	File_yandex_cloud_ai_tts_v3_tts_proto = out.File
	file_yandex_cloud_ai_tts_v3_tts_proto_goTypes = nil
	file_yandex_cloud_ai_tts_v3_tts_proto_depIdxs = nil
}

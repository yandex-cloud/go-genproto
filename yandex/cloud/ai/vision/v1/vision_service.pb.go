// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        v3.21.12
// source: yandex/cloud/ai/vision/v1/vision_service.proto

package vision

import (
	_ "github.com/yandex-cloud/go-genproto/yandex/cloud"
	_ "google.golang.org/genproto/googleapis/api/annotations"
	status "google.golang.org/genproto/googleapis/rpc/status"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type Feature_Type int32

const (
	Feature_TYPE_UNSPECIFIED Feature_Type = 0
	// Text detection (OCR) feature.
	Feature_TEXT_DETECTION Feature_Type = 1
	// Classification feature.
	Feature_CLASSIFICATION Feature_Type = 2
	// Face detection feature.
	Feature_FACE_DETECTION Feature_Type = 3
	// Image copy search.
	Feature_IMAGE_COPY_SEARCH Feature_Type = 4
)

// Enum value maps for Feature_Type.
var (
	Feature_Type_name = map[int32]string{
		0: "TYPE_UNSPECIFIED",
		1: "TEXT_DETECTION",
		2: "CLASSIFICATION",
		3: "FACE_DETECTION",
		4: "IMAGE_COPY_SEARCH",
	}
	Feature_Type_value = map[string]int32{
		"TYPE_UNSPECIFIED":  0,
		"TEXT_DETECTION":    1,
		"CLASSIFICATION":    2,
		"FACE_DETECTION":    3,
		"IMAGE_COPY_SEARCH": 4,
	}
)

func (x Feature_Type) Enum() *Feature_Type {
	p := new(Feature_Type)
	*p = x
	return p
}

func (x Feature_Type) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Feature_Type) Descriptor() protoreflect.EnumDescriptor {
	return file_yandex_cloud_ai_vision_v1_vision_service_proto_enumTypes[0].Descriptor()
}

func (Feature_Type) Type() protoreflect.EnumType {
	return &file_yandex_cloud_ai_vision_v1_vision_service_proto_enumTypes[0]
}

func (x Feature_Type) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Feature_Type.Descriptor instead.
func (Feature_Type) EnumDescriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDescGZIP(), []int{2, 0}
}

type BatchAnalyzeRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A list of specifications. Each specification contains the file to analyze and features to use for analysis.
	//
	// Restrictions:
	// * Supported file formats: `JPEG`, `PNG`.
	// * Maximum file size: 1 MB.
	// * Image size should not exceed 20M pixels (length x width).
	AnalyzeSpecs []*AnalyzeSpec `protobuf:"bytes,1,rep,name=analyze_specs,json=analyzeSpecs,proto3" json:"analyze_specs,omitempty"`
	// ID of the folder to which you have access.
	// Required for authorization with a user account.
	// Don't specify this field if you make the request on behalf of a service account.
	FolderId      string `protobuf:"bytes,2,opt,name=folder_id,json=folderId,proto3" json:"folder_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BatchAnalyzeRequest) Reset() {
	*x = BatchAnalyzeRequest{}
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BatchAnalyzeRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BatchAnalyzeRequest) ProtoMessage() {}

func (x *BatchAnalyzeRequest) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BatchAnalyzeRequest.ProtoReflect.Descriptor instead.
func (*BatchAnalyzeRequest) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDescGZIP(), []int{0}
}

func (x *BatchAnalyzeRequest) GetAnalyzeSpecs() []*AnalyzeSpec {
	if x != nil {
		return x.AnalyzeSpecs
	}
	return nil
}

func (x *BatchAnalyzeRequest) GetFolderId() string {
	if x != nil {
		return x.FolderId
	}
	return ""
}

type AnalyzeSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Source:
	//
	//	*AnalyzeSpec_Content
	//	*AnalyzeSpec_Signature
	Source isAnalyzeSpec_Source `protobuf_oneof:"source"`
	// Requested features to use for analysis.
	//
	// Max count of requested features for one file is 8.
	Features []*Feature `protobuf:"bytes,3,rep,name=features,proto3" json:"features,omitempty"`
	// [MIME type](https://en.wikipedia.org/wiki/Media_type) of content (for example, “ application/pdf “).
	MimeType      string `protobuf:"bytes,4,opt,name=mime_type,json=mimeType,proto3" json:"mime_type,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AnalyzeSpec) Reset() {
	*x = AnalyzeSpec{}
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AnalyzeSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AnalyzeSpec) ProtoMessage() {}

func (x *AnalyzeSpec) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AnalyzeSpec.ProtoReflect.Descriptor instead.
func (*AnalyzeSpec) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDescGZIP(), []int{1}
}

func (x *AnalyzeSpec) GetSource() isAnalyzeSpec_Source {
	if x != nil {
		return x.Source
	}
	return nil
}

func (x *AnalyzeSpec) GetContent() []byte {
	if x != nil {
		if x, ok := x.Source.(*AnalyzeSpec_Content); ok {
			return x.Content
		}
	}
	return nil
}

func (x *AnalyzeSpec) GetSignature() string {
	if x != nil {
		if x, ok := x.Source.(*AnalyzeSpec_Signature); ok {
			return x.Signature
		}
	}
	return ""
}

func (x *AnalyzeSpec) GetFeatures() []*Feature {
	if x != nil {
		return x.Features
	}
	return nil
}

func (x *AnalyzeSpec) GetMimeType() string {
	if x != nil {
		return x.MimeType
	}
	return ""
}

type isAnalyzeSpec_Source interface {
	isAnalyzeSpec_Source()
}

type AnalyzeSpec_Content struct {
	// Image content, represented as a stream of bytes.
	// Note: As with all bytes fields, protobuffers use a pure binary representation, whereas JSON representations use base64.
	Content []byte `protobuf:"bytes,1,opt,name=content,proto3,oneof"`
}

type AnalyzeSpec_Signature struct {
	Signature string `protobuf:"bytes,5,opt,name=signature,proto3,oneof"`
}

func (*AnalyzeSpec_Content) isAnalyzeSpec_Source() {}

func (*AnalyzeSpec_Signature) isAnalyzeSpec_Source() {}

type Feature struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Type of requested feature.
	Type Feature_Type `protobuf:"varint,1,opt,name=type,proto3,enum=yandex.cloud.ai.vision.v1.Feature_Type" json:"type,omitempty"`
	// Types that are valid to be assigned to Config:
	//
	//	*Feature_ClassificationConfig
	//	*Feature_TextDetectionConfig
	Config        isFeature_Config `protobuf_oneof:"config"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Feature) Reset() {
	*x = Feature{}
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Feature) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Feature) ProtoMessage() {}

func (x *Feature) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Feature.ProtoReflect.Descriptor instead.
func (*Feature) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDescGZIP(), []int{2}
}

func (x *Feature) GetType() Feature_Type {
	if x != nil {
		return x.Type
	}
	return Feature_TYPE_UNSPECIFIED
}

func (x *Feature) GetConfig() isFeature_Config {
	if x != nil {
		return x.Config
	}
	return nil
}

func (x *Feature) GetClassificationConfig() *FeatureClassificationConfig {
	if x != nil {
		if x, ok := x.Config.(*Feature_ClassificationConfig); ok {
			return x.ClassificationConfig
		}
	}
	return nil
}

func (x *Feature) GetTextDetectionConfig() *FeatureTextDetectionConfig {
	if x != nil {
		if x, ok := x.Config.(*Feature_TextDetectionConfig); ok {
			return x.TextDetectionConfig
		}
	}
	return nil
}

type isFeature_Config interface {
	isFeature_Config()
}

type Feature_ClassificationConfig struct {
	// Required for the `CLASSIFICATION` type. Specifies configuration for the classification feature.
	ClassificationConfig *FeatureClassificationConfig `protobuf:"bytes,2,opt,name=classification_config,json=classificationConfig,proto3,oneof"`
}

type Feature_TextDetectionConfig struct {
	// Required for the `TEXT_DETECTION` type. Specifies configuration for the text detection (OCR) feature.
	TextDetectionConfig *FeatureTextDetectionConfig `protobuf:"bytes,3,opt,name=text_detection_config,json=textDetectionConfig,proto3,oneof"`
}

func (*Feature_ClassificationConfig) isFeature_Config() {}

func (*Feature_TextDetectionConfig) isFeature_Config() {}

type FeatureClassificationConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Model to use for image classification.
	Model         string `protobuf:"bytes,1,opt,name=model,proto3" json:"model,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FeatureClassificationConfig) Reset() {
	*x = FeatureClassificationConfig{}
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FeatureClassificationConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FeatureClassificationConfig) ProtoMessage() {}

func (x *FeatureClassificationConfig) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FeatureClassificationConfig.ProtoReflect.Descriptor instead.
func (*FeatureClassificationConfig) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDescGZIP(), []int{3}
}

func (x *FeatureClassificationConfig) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

type FeatureTextDetectionConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// List of the languages to recognize text.
	// Specified in [ISO 639-1](https://en.wikipedia.org/wiki/ISO_639-1) format (for example, `ru`).
	LanguageCodes []string `protobuf:"bytes,1,rep,name=language_codes,json=languageCodes,proto3" json:"language_codes,omitempty"`
	// Model to use for text detection.
	// Possible values:
	// * `page` (default): this model is suitable for detecting multiple text entries in an image.
	// * `line`: this model is suitable for cropped images with one line of text.
	Model         string `protobuf:"bytes,2,opt,name=model,proto3" json:"model,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FeatureTextDetectionConfig) Reset() {
	*x = FeatureTextDetectionConfig{}
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FeatureTextDetectionConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FeatureTextDetectionConfig) ProtoMessage() {}

func (x *FeatureTextDetectionConfig) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FeatureTextDetectionConfig.ProtoReflect.Descriptor instead.
func (*FeatureTextDetectionConfig) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDescGZIP(), []int{4}
}

func (x *FeatureTextDetectionConfig) GetLanguageCodes() []string {
	if x != nil {
		return x.LanguageCodes
	}
	return nil
}

func (x *FeatureTextDetectionConfig) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

type BatchAnalyzeResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Request results.
	// Results have the same order as specifications in the request.
	Results       []*AnalyzeResult `protobuf:"bytes,1,rep,name=results,proto3" json:"results,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BatchAnalyzeResponse) Reset() {
	*x = BatchAnalyzeResponse{}
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BatchAnalyzeResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BatchAnalyzeResponse) ProtoMessage() {}

func (x *BatchAnalyzeResponse) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BatchAnalyzeResponse.ProtoReflect.Descriptor instead.
func (*BatchAnalyzeResponse) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDescGZIP(), []int{5}
}

func (x *BatchAnalyzeResponse) GetResults() []*AnalyzeResult {
	if x != nil {
		return x.Results
	}
	return nil
}

type AnalyzeResult struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Results for each requested feature.
	// Feature results have the same order as in the request.
	Results []*FeatureResult `protobuf:"bytes,2,rep,name=results,proto3" json:"results,omitempty"`
	// Return error in case of error with file processing.
	Error         *status.Status `protobuf:"bytes,1,opt,name=error,proto3" json:"error,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AnalyzeResult) Reset() {
	*x = AnalyzeResult{}
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AnalyzeResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AnalyzeResult) ProtoMessage() {}

func (x *AnalyzeResult) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AnalyzeResult.ProtoReflect.Descriptor instead.
func (*AnalyzeResult) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDescGZIP(), []int{6}
}

func (x *AnalyzeResult) GetResults() []*FeatureResult {
	if x != nil {
		return x.Results
	}
	return nil
}

func (x *AnalyzeResult) GetError() *status.Status {
	if x != nil {
		return x.Error
	}
	return nil
}

type FeatureResult struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Feature:
	//
	//	*FeatureResult_TextDetection
	//	*FeatureResult_Classification
	//	*FeatureResult_FaceDetection
	//	*FeatureResult_ImageCopySearch
	Feature isFeatureResult_Feature `protobuf_oneof:"feature"`
	// Return error in case of error during the specified feature processing.
	Error         *status.Status `protobuf:"bytes,1,opt,name=error,proto3" json:"error,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FeatureResult) Reset() {
	*x = FeatureResult{}
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FeatureResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FeatureResult) ProtoMessage() {}

func (x *FeatureResult) ProtoReflect() protoreflect.Message {
	mi := &file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FeatureResult.ProtoReflect.Descriptor instead.
func (*FeatureResult) Descriptor() ([]byte, []int) {
	return file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDescGZIP(), []int{7}
}

func (x *FeatureResult) GetFeature() isFeatureResult_Feature {
	if x != nil {
		return x.Feature
	}
	return nil
}

func (x *FeatureResult) GetTextDetection() *TextAnnotation {
	if x != nil {
		if x, ok := x.Feature.(*FeatureResult_TextDetection); ok {
			return x.TextDetection
		}
	}
	return nil
}

func (x *FeatureResult) GetClassification() *ClassAnnotation {
	if x != nil {
		if x, ok := x.Feature.(*FeatureResult_Classification); ok {
			return x.Classification
		}
	}
	return nil
}

func (x *FeatureResult) GetFaceDetection() *FaceAnnotation {
	if x != nil {
		if x, ok := x.Feature.(*FeatureResult_FaceDetection); ok {
			return x.FaceDetection
		}
	}
	return nil
}

func (x *FeatureResult) GetImageCopySearch() *ImageCopySearchAnnotation {
	if x != nil {
		if x, ok := x.Feature.(*FeatureResult_ImageCopySearch); ok {
			return x.ImageCopySearch
		}
	}
	return nil
}

func (x *FeatureResult) GetError() *status.Status {
	if x != nil {
		return x.Error
	}
	return nil
}

type isFeatureResult_Feature interface {
	isFeatureResult_Feature()
}

type FeatureResult_TextDetection struct {
	// Text detection (OCR) result.
	TextDetection *TextAnnotation `protobuf:"bytes,2,opt,name=text_detection,json=textDetection,proto3,oneof"`
}

type FeatureResult_Classification struct {
	// Classification result.
	Classification *ClassAnnotation `protobuf:"bytes,3,opt,name=classification,proto3,oneof"`
}

type FeatureResult_FaceDetection struct {
	// Face detection result.
	FaceDetection *FaceAnnotation `protobuf:"bytes,4,opt,name=face_detection,json=faceDetection,proto3,oneof"`
}

type FeatureResult_ImageCopySearch struct {
	// Image Copy Search result.
	ImageCopySearch *ImageCopySearchAnnotation `protobuf:"bytes,5,opt,name=image_copy_search,json=imageCopySearch,proto3,oneof"`
}

func (*FeatureResult_TextDetection) isFeatureResult_Feature() {}

func (*FeatureResult_Classification) isFeatureResult_Feature() {}

func (*FeatureResult_FaceDetection) isFeatureResult_Feature() {}

func (*FeatureResult_ImageCopySearch) isFeatureResult_Feature() {}

var File_yandex_cloud_ai_vision_v1_vision_service_proto protoreflect.FileDescriptor

const file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDesc = "" +
	"\n" +
	".yandex/cloud/ai/vision/v1/vision_service.proto\x12\x19yandex.cloud.ai.vision.v1\x1a.yandex/cloud/ai/vision/v1/text_detection.proto\x1a.yandex/cloud/ai/vision/v1/classification.proto\x1a.yandex/cloud/ai/vision/v1/face_detection.proto\x1a1yandex/cloud/ai/vision/v1/image_copy_search.proto\x1a\x1dyandex/cloud/validation.proto\x1a\x1cgoogle/api/annotations.proto\x1a\x17google/rpc/status.proto\"\x92\x01\n" +
	"\x13BatchAnalyzeRequest\x12T\n" +
	"\ranalyze_specs\x18\x01 \x03(\v2&.yandex.cloud.ai.vision.v1.AnalyzeSpecB\a\x82\xc81\x031-8R\fanalyzeSpecs\x12%\n" +
	"\tfolder_id\x18\x02 \x01(\tB\b\x8a\xc81\x04<=50R\bfolderId\"\xed\x01\n" +
	"\vAnalyzeSpec\x12*\n" +
	"\acontent\x18\x01 \x01(\fB\x0e\x8a\xc81\n" +
	"<=10485760H\x00R\acontent\x12+\n" +
	"\tsignature\x18\x05 \x01(\tB\v\x8a\xc81\a<=16384H\x00R\tsignature\x12G\n" +
	"\bfeatures\x18\x03 \x03(\v2\".yandex.cloud.ai.vision.v1.FeatureB\a\x82\xc81\x031-8R\bfeatures\x12&\n" +
	"\tmime_type\x18\x04 \x01(\tB\t\x8a\xc81\x05<=255R\bmimeTypeB\x0e\n" +
	"\x06source\x12\x04\xc0\xc11\x01J\x04\b\x02\x10\x03\"\x9d\x03\n" +
	"\aFeature\x12;\n" +
	"\x04type\x18\x01 \x01(\x0e2'.yandex.cloud.ai.vision.v1.Feature.TypeR\x04type\x12m\n" +
	"\x15classification_config\x18\x02 \x01(\v26.yandex.cloud.ai.vision.v1.FeatureClassificationConfigH\x00R\x14classificationConfig\x12k\n" +
	"\x15text_detection_config\x18\x03 \x01(\v25.yandex.cloud.ai.vision.v1.FeatureTextDetectionConfigH\x00R\x13textDetectionConfig\"o\n" +
	"\x04Type\x12\x14\n" +
	"\x10TYPE_UNSPECIFIED\x10\x00\x12\x12\n" +
	"\x0eTEXT_DETECTION\x10\x01\x12\x12\n" +
	"\x0eCLASSIFICATION\x10\x02\x12\x12\n" +
	"\x0eFACE_DETECTION\x10\x03\x12\x15\n" +
	"\x11IMAGE_COPY_SEARCH\x10\x04B\b\n" +
	"\x06config\">\n" +
	"\x1bFeatureClassificationConfig\x12\x1f\n" +
	"\x05model\x18\x01 \x01(\tB\t\x8a\xc81\x05<=256R\x05model\"s\n" +
	"\x1aFeatureTextDetectionConfig\x125\n" +
	"\x0elanguage_codes\x18\x01 \x03(\tB\x0e\x82\xc81\x031-8\x8a\xc81\x03<=3R\rlanguageCodes\x12\x1e\n" +
	"\x05model\x18\x02 \x01(\tB\b\x8a\xc81\x04<=50R\x05model\"Z\n" +
	"\x14BatchAnalyzeResponse\x12B\n" +
	"\aresults\x18\x01 \x03(\v2(.yandex.cloud.ai.vision.v1.AnalyzeResultR\aresults\"}\n" +
	"\rAnalyzeResult\x12B\n" +
	"\aresults\x18\x02 \x03(\v2(.yandex.cloud.ai.vision.v1.FeatureResultR\aresults\x12(\n" +
	"\x05error\x18\x01 \x01(\v2\x12.google.rpc.StatusR\x05error\"\xa6\x03\n" +
	"\rFeatureResult\x12R\n" +
	"\x0etext_detection\x18\x02 \x01(\v2).yandex.cloud.ai.vision.v1.TextAnnotationH\x00R\rtextDetection\x12T\n" +
	"\x0eclassification\x18\x03 \x01(\v2*.yandex.cloud.ai.vision.v1.ClassAnnotationH\x00R\x0eclassification\x12R\n" +
	"\x0eface_detection\x18\x04 \x01(\v2).yandex.cloud.ai.vision.v1.FaceAnnotationH\x00R\rfaceDetection\x12b\n" +
	"\x11image_copy_search\x18\x05 \x01(\v24.yandex.cloud.ai.vision.v1.ImageCopySearchAnnotationH\x00R\x0fimageCopySearch\x12(\n" +
	"\x05error\x18\x01 \x01(\v2\x12.google.rpc.StatusR\x05errorB\t\n" +
	"\afeature2\xa5\x01\n" +
	"\rVisionService\x12\x93\x01\n" +
	"\fBatchAnalyze\x12..yandex.cloud.ai.vision.v1.BatchAnalyzeRequest\x1a/.yandex.cloud.ai.vision.v1.BatchAnalyzeResponse\"\"\x82\xd3\xe4\x93\x02\x1c:\x01*\"\x17/vision/v1/batchAnalyzeBe\n" +
	"\x1dyandex.cloud.api.ai.vision.v1ZDgithub.com/yandex-cloud/go-genproto/yandex/cloud/ai/vision/v1;visionb\x06proto3"

var (
	file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDescOnce sync.Once
	file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDescData []byte
)

func file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDescGZIP() []byte {
	file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDescOnce.Do(func() {
		file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDesc), len(file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDesc)))
	})
	return file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDescData
}

var file_yandex_cloud_ai_vision_v1_vision_service_proto_enumTypes = make([]protoimpl.EnumInfo, 1)
var file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes = make([]protoimpl.MessageInfo, 8)
var file_yandex_cloud_ai_vision_v1_vision_service_proto_goTypes = []any{
	(Feature_Type)(0),                   // 0: yandex.cloud.ai.vision.v1.Feature.Type
	(*BatchAnalyzeRequest)(nil),         // 1: yandex.cloud.ai.vision.v1.BatchAnalyzeRequest
	(*AnalyzeSpec)(nil),                 // 2: yandex.cloud.ai.vision.v1.AnalyzeSpec
	(*Feature)(nil),                     // 3: yandex.cloud.ai.vision.v1.Feature
	(*FeatureClassificationConfig)(nil), // 4: yandex.cloud.ai.vision.v1.FeatureClassificationConfig
	(*FeatureTextDetectionConfig)(nil),  // 5: yandex.cloud.ai.vision.v1.FeatureTextDetectionConfig
	(*BatchAnalyzeResponse)(nil),        // 6: yandex.cloud.ai.vision.v1.BatchAnalyzeResponse
	(*AnalyzeResult)(nil),               // 7: yandex.cloud.ai.vision.v1.AnalyzeResult
	(*FeatureResult)(nil),               // 8: yandex.cloud.ai.vision.v1.FeatureResult
	(*status.Status)(nil),               // 9: google.rpc.Status
	(*TextAnnotation)(nil),              // 10: yandex.cloud.ai.vision.v1.TextAnnotation
	(*ClassAnnotation)(nil),             // 11: yandex.cloud.ai.vision.v1.ClassAnnotation
	(*FaceAnnotation)(nil),              // 12: yandex.cloud.ai.vision.v1.FaceAnnotation
	(*ImageCopySearchAnnotation)(nil),   // 13: yandex.cloud.ai.vision.v1.ImageCopySearchAnnotation
}
var file_yandex_cloud_ai_vision_v1_vision_service_proto_depIdxs = []int32{
	2,  // 0: yandex.cloud.ai.vision.v1.BatchAnalyzeRequest.analyze_specs:type_name -> yandex.cloud.ai.vision.v1.AnalyzeSpec
	3,  // 1: yandex.cloud.ai.vision.v1.AnalyzeSpec.features:type_name -> yandex.cloud.ai.vision.v1.Feature
	0,  // 2: yandex.cloud.ai.vision.v1.Feature.type:type_name -> yandex.cloud.ai.vision.v1.Feature.Type
	4,  // 3: yandex.cloud.ai.vision.v1.Feature.classification_config:type_name -> yandex.cloud.ai.vision.v1.FeatureClassificationConfig
	5,  // 4: yandex.cloud.ai.vision.v1.Feature.text_detection_config:type_name -> yandex.cloud.ai.vision.v1.FeatureTextDetectionConfig
	7,  // 5: yandex.cloud.ai.vision.v1.BatchAnalyzeResponse.results:type_name -> yandex.cloud.ai.vision.v1.AnalyzeResult
	8,  // 6: yandex.cloud.ai.vision.v1.AnalyzeResult.results:type_name -> yandex.cloud.ai.vision.v1.FeatureResult
	9,  // 7: yandex.cloud.ai.vision.v1.AnalyzeResult.error:type_name -> google.rpc.Status
	10, // 8: yandex.cloud.ai.vision.v1.FeatureResult.text_detection:type_name -> yandex.cloud.ai.vision.v1.TextAnnotation
	11, // 9: yandex.cloud.ai.vision.v1.FeatureResult.classification:type_name -> yandex.cloud.ai.vision.v1.ClassAnnotation
	12, // 10: yandex.cloud.ai.vision.v1.FeatureResult.face_detection:type_name -> yandex.cloud.ai.vision.v1.FaceAnnotation
	13, // 11: yandex.cloud.ai.vision.v1.FeatureResult.image_copy_search:type_name -> yandex.cloud.ai.vision.v1.ImageCopySearchAnnotation
	9,  // 12: yandex.cloud.ai.vision.v1.FeatureResult.error:type_name -> google.rpc.Status
	1,  // 13: yandex.cloud.ai.vision.v1.VisionService.BatchAnalyze:input_type -> yandex.cloud.ai.vision.v1.BatchAnalyzeRequest
	6,  // 14: yandex.cloud.ai.vision.v1.VisionService.BatchAnalyze:output_type -> yandex.cloud.ai.vision.v1.BatchAnalyzeResponse
	14, // [14:15] is the sub-list for method output_type
	13, // [13:14] is the sub-list for method input_type
	13, // [13:13] is the sub-list for extension type_name
	13, // [13:13] is the sub-list for extension extendee
	0,  // [0:13] is the sub-list for field type_name
}

func init() { file_yandex_cloud_ai_vision_v1_vision_service_proto_init() }
func file_yandex_cloud_ai_vision_v1_vision_service_proto_init() {
	if File_yandex_cloud_ai_vision_v1_vision_service_proto != nil {
		return
	}
	file_yandex_cloud_ai_vision_v1_text_detection_proto_init()
	file_yandex_cloud_ai_vision_v1_classification_proto_init()
	file_yandex_cloud_ai_vision_v1_face_detection_proto_init()
	file_yandex_cloud_ai_vision_v1_image_copy_search_proto_init()
	file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[1].OneofWrappers = []any{
		(*AnalyzeSpec_Content)(nil),
		(*AnalyzeSpec_Signature)(nil),
	}
	file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[2].OneofWrappers = []any{
		(*Feature_ClassificationConfig)(nil),
		(*Feature_TextDetectionConfig)(nil),
	}
	file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes[7].OneofWrappers = []any{
		(*FeatureResult_TextDetection)(nil),
		(*FeatureResult_Classification)(nil),
		(*FeatureResult_FaceDetection)(nil),
		(*FeatureResult_ImageCopySearch)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDesc), len(file_yandex_cloud_ai_vision_v1_vision_service_proto_rawDesc)),
			NumEnums:      1,
			NumMessages:   8,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_yandex_cloud_ai_vision_v1_vision_service_proto_goTypes,
		DependencyIndexes: file_yandex_cloud_ai_vision_v1_vision_service_proto_depIdxs,
		EnumInfos:         file_yandex_cloud_ai_vision_v1_vision_service_proto_enumTypes,
		MessageInfos:      file_yandex_cloud_ai_vision_v1_vision_service_proto_msgTypes,
	}.Build()
	File_yandex_cloud_ai_vision_v1_vision_service_proto = out.File
	file_yandex_cloud_ai_vision_v1_vision_service_proto_goTypes = nil
	file_yandex_cloud_ai_vision_v1_vision_service_proto_depIdxs = nil
}
